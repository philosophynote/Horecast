{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dbae3e7-3e93-4799-af7c-f2c3475094f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#親クラスの読み込み\n",
    "from DP import DataProcessor\n",
    "from Result import Results\n",
    "from HR import HorseResults\n",
    "from Ped import Peds\n",
    "from ST import ShutubaTable\n",
    "from JR import JockeyResults\n",
    "from TR import TrainerResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaa7877-e394-4cc1-839c-d876b3b4fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリをインポート\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b257d813-179a-4e04-8d9c-546c5d7ad23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Results.read_pickle(['data/race_results_11_20.pickle'])\n",
    "hr = HorseResults.read_pickle(['data/horse_results_all.pickle'])\n",
    "p = Peds.read_pickle(['data/peds_all.pickle'])\n",
    "jr = JockeyResults.read_pickle(['data/jockey_results.pickle'])\n",
    "tr = TrainerResults.read_pickle(['data/trainer_results.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3bded7-c8a3-4b10-9978-114eb9630a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afc91c3-9dc3-4d29-a719-1a585288e339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6815cb9feb6c448aaeeaf5385b7e2271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_horse_results(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bc26df-4dc5-4902-832e-906bdcc63e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.encode()\n",
    "r.merge_peds(p.peds_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da5bfcf-4fbc-455b-82f9-0d96f1bb7cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcde4cf65b1462799dc1b6a3193dbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_jockey(jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccee2812-c466-4d98-8163-11433d83c2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1d3d6a0e424982b0c17a5d2bd32b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_trainer(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ff2f87-e80c-40e4-8b7d-046cb3300a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.process_categorical() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e9afbe8-cb10-44ef-a7fa-0a761efc35ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>prize</th>\n",
       "      <th>course_len</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>rank_1R_before</th>\n",
       "      <th>money_1R_before</th>\n",
       "      <th>favorite_1R_before</th>\n",
       "      <th>last_1R_before</th>\n",
       "      <th>odds_1R_before</th>\n",
       "      <th>final_corner_1R_before</th>\n",
       "      <th>rank_2R_before</th>\n",
       "      <th>money_2R_before</th>\n",
       "      <th>favorite_2R_before</th>\n",
       "      <th>last_2R_before</th>\n",
       "      <th>odds_2R_before</th>\n",
       "      <th>final_corner_2R_before</th>\n",
       "      <th>rank_3R_before</th>\n",
       "      <th>money_3R_before</th>\n",
       "      <th>favorite_3R_before</th>\n",
       "      <th>last_3R_before</th>\n",
       "      <th>odds_3R_before</th>\n",
       "      <th>final_corner_3R_before</th>\n",
       "      <th>course_len_all</th>\n",
       "      <th>time_rank_p</th>\n",
       "      <th>interval</th>\n",
       "      <th>course_len_dif</th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>win_rate_1_1Y_before_j</th>\n",
       "      <th>win_rate_3_1Y_before_j</th>\n",
       "      <th>prize_1Y_before_j</th>\n",
       "      <th>win_rate_1_1Y_before_t</th>\n",
       "      <th>win_rate_3_1Y_before_t</th>\n",
       "      <th>prize_1Y_before_t</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>sex_牡</th>\n",
       "      <th>sex_牝</th>\n",
       "      <th>sex_セ</th>\n",
       "      <th>race_park_札幌</th>\n",
       "      <th>race_park_新潟</th>\n",
       "      <th>race_park_小倉</th>\n",
       "      <th>race_park_中山</th>\n",
       "      <th>race_park_阪神</th>\n",
       "      <th>race_park_函館</th>\n",
       "      <th>race_park_京都</th>\n",
       "      <th>race_park_東京</th>\n",
       "      <th>race_park_中京</th>\n",
       "      <th>race_park_福島</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>778</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.240</td>\n",
       "      <td>96905.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.140</td>\n",
       "      <td>16330.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762</td>\n",
       "      <td>1634</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.333</td>\n",
       "      <td>188832.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.400</td>\n",
       "      <td>52106.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.262</td>\n",
       "      <td>137964.6</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.168</td>\n",
       "      <td>23638.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>778</td>\n",
       "      <td>1639</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.194</td>\n",
       "      <td>95243.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.292</td>\n",
       "      <td>108027.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>968</td>\n",
       "      <td>1888</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>114614.3</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.167</td>\n",
       "      <td>23687.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  frame_number  horse_number  age  weight_j  \\\n",
       "201101010101     0   4.7       3.0             2             2    2      54.0   \n",
       "201101010101     0   3.4       2.0             3             3    2      54.0   \n",
       "201101010101     0   2.1       1.0             5             5    2      54.0   \n",
       "201101010101     1   7.0       4.0             4             4    2      54.0   \n",
       "201101010101     1  17.5       5.0             1             1    2      54.0   \n",
       "\n",
       "              prize  course_len  n_horses       date    horse_id jockey_id  \\\n",
       "201101010101  500.0          18         7 2011-08-13  2009105006     01019   \n",
       "201101010101  500.0          18         7 2011-08-13  2009100577     05203   \n",
       "201101010101  500.0          18         7 2011-08-13  2009102908     01093   \n",
       "201101010101  500.0          18         7 2011-08-13  2009109159     01095   \n",
       "201101010101  500.0          18         7 2011-08-13  2009105263     01127   \n",
       "\n",
       "             trainer_id  rank_1R_before  money_1R_before  favorite_1R_before  \\\n",
       "201101010101      00379             8.0              0.0                 8.0   \n",
       "201101010101      01061             NaN              NaN                 NaN   \n",
       "201101010101      01089             NaN              NaN                 NaN   \n",
       "201101010101      01075             NaN              NaN                 NaN   \n",
       "201101010101      01026             NaN              NaN                 NaN   \n",
       "\n",
       "              last_1R_before  odds_1R_before  final_corner_1R_before  \\\n",
       "201101010101            34.7            28.8                    10.0   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_2R_before  money_2R_before  favorite_2R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_2R_before  odds_2R_before  final_corner_2R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_3R_before  money_3R_before  favorite_3R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_3R_before  odds_3R_before  final_corner_3R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              course_len_all  time_rank_p  interval  course_len_dif peds_0  \\\n",
       "201101010101            14.0          1.0      34.0             4.0    778   \n",
       "201101010101             NaN          NaN       NaN             NaN    762   \n",
       "201101010101             NaN          NaN       NaN             NaN    788   \n",
       "201101010101             NaN          NaN       NaN             NaN    778   \n",
       "201101010101             NaN          NaN       NaN             NaN    968   \n",
       "\n",
       "             peds_4  win_rate_1_1Y_before_j  win_rate_3_1Y_before_j  \\\n",
       "201101010101   1454                   0.084                   0.240   \n",
       "201101010101   1634                   0.119                   0.333   \n",
       "201101010101   1454                   0.086                   0.262   \n",
       "201101010101   1639                   0.069                   0.194   \n",
       "201101010101   1888                   0.110                   0.284   \n",
       "\n",
       "              prize_1Y_before_j  win_rate_1_1Y_before_t  \\\n",
       "201101010101            96905.1                   0.062   \n",
       "201101010101           188832.6                   0.138   \n",
       "201101010101           137964.6                   0.051   \n",
       "201101010101            95243.0                   0.087   \n",
       "201101010101           114614.3                   0.062   \n",
       "\n",
       "              win_rate_3_1Y_before_t  prize_1Y_before_t  race_type_芝  \\\n",
       "201101010101                   0.140            16330.6            1   \n",
       "201101010101                   0.400            52106.2            1   \n",
       "201101010101                   0.168            23638.6            1   \n",
       "201101010101                   0.292           108027.3            1   \n",
       "201101010101                   0.167            23687.4            1   \n",
       "\n",
       "              race_type_ダート  race_type_障害  sex_牡  sex_牝  sex_セ  race_park_札幌  \\\n",
       "201101010101              0             0      1      0      0             1   \n",
       "201101010101              0             0      1      0      0             1   \n",
       "201101010101              0             0      1      0      0             1   \n",
       "201101010101              0             0      1      0      0             1   \n",
       "201101010101              0             0      0      1      0             1   \n",
       "\n",
       "              race_park_新潟  race_park_小倉  race_park_中山  race_park_阪神  \\\n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "\n",
       "              race_park_函館  race_park_京都  race_park_東京  race_park_中京  \\\n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "\n",
       "              race_park_福島  \n",
       "201101010101             0  \n",
       "201101010101             0  \n",
       "201101010101             0  \n",
       "201101010101             0  \n",
       "201101010101             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b00740bb-090e-4053-a4c0-5f6e76b94c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_e = r.data_c[((r.data_c[\"rank\"]==0) & (r.data_c[\"odds\"]<=32.0)) | (r.data_c[\"rank\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39398adc-3fb5-4d2b-920f-30aaff97078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d = r.data_e[((r.data_e[\"rank\"]==0) & (r.data_e[\"favorite\"]<=10)) | (r.data_e[\"rank\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f62298f8-48c1-4edc-b548-adbe9ee173e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]\n",
    "    test = df.loc[test_id_list]\n",
    "    return train, test\n",
    "\n",
    "train, test = split_data(r.data_d)\n",
    "\n",
    "train, valid = split_data(train)\n",
    "\n",
    "X_train = train.drop(['rank', 'date',\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_train = train['rank']\n",
    "X_valid = valid.drop(['rank', 'date',\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_valid = valid['rank']\n",
    "\n",
    "#データセットを作成\n",
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_valid = lgb_o.Dataset(X_valid.values, y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "148e32c0-4fdc-44dd-add1-ef3d65693f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary', #今回は0or1の二値予測なのでbinaryを指定\n",
    "    'random_state': 100,\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a272acc2-7d0c-4151-bd43-f5c7c267ab9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-03 11:00:25,215]\u001b[0m A new study created in memory with name: no-name-3a921870-bcb4-439a-9ff9-a3f2e4dc79fb\u001b[0m\n",
      "feature_fraction, val_score: -inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78831\tvalid_1's auc: 0.815649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815940:  14%|#4        | 1/7 [00:04<00:25,  4.23s/it]\u001b[32m[I 2021-11-03 11:00:29,458]\u001b[0m Trial 0 finished with value: 0.8159398662301898 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8159398662301898.\u001b[0m\n",
      "feature_fraction, val_score: 0.815940:  14%|#4        | 1/7 [00:04<00:25,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.79271\tvalid_1's auc: 0.81594\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.788223\tvalid_1's auc: 0.815098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815940:  29%|##8       | 2/7 [00:08<00:20,  4.05s/it]\u001b[32m[I 2021-11-03 11:00:33,382]\u001b[0m Trial 1 finished with value: 0.8155621880311953 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8159398662301898.\u001b[0m\n",
      "feature_fraction, val_score: 0.815940:  29%|##8       | 2/7 [00:08<00:20,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.792408\tvalid_1's auc: 0.815562\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010089 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.789757\tvalid_1's auc: 0.815195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815940:  43%|####2     | 3/7 [00:11<00:15,  3.95s/it]\u001b[32m[I 2021-11-03 11:00:37,208]\u001b[0m Trial 2 finished with value: 0.8153758718042835 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.8159398662301898.\u001b[0m\n",
      "feature_fraction, val_score: 0.815940:  43%|####2     | 3/7 [00:11<00:15,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.791868\tvalid_1's auc: 0.815376\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.789755\tvalid_1's auc: 0.814958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815940:  57%|#####7    | 4/7 [00:16<00:12,  4.00s/it]\u001b[32m[I 2021-11-03 11:00:41,299]\u001b[0m Trial 3 finished with value: 0.8152976822538424 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8159398662301898.\u001b[0m\n",
      "feature_fraction, val_score: 0.815940:  57%|#####7    | 4/7 [00:16<00:12,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.796792\tvalid_1's auc: 0.815298\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786715\tvalid_1's auc: 0.81556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.816119:  71%|#######1  | 5/7 [00:20<00:08,  4.01s/it]\u001b[32m[I 2021-11-03 11:00:45,312]\u001b[0m Trial 4 finished with value: 0.8161187901167307 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.8161187901167307.\u001b[0m\n",
      "feature_fraction, val_score: 0.816119:  71%|#######1  | 5/7 [00:20<00:08,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.792783\tvalid_1's auc: 0.816119\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78925\tvalid_1's auc: 0.815371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.816119:  86%|########5 | 6/7 [00:23<00:03,  3.86s/it]\u001b[32m[I 2021-11-03 11:00:48,889]\u001b[0m Trial 5 finished with value: 0.8155077939778645 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.8161187901167307.\u001b[0m\n",
      "feature_fraction, val_score: 0.816119:  86%|########5 | 6/7 [00:23<00:03,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.790417\tvalid_1's auc: 0.815508\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.787803\tvalid_1's auc: 0.815435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.816119: 100%|##########| 7/7 [00:27<00:00,  3.93s/it]\u001b[32m[I 2021-11-03 11:00:52,966]\u001b[0m Trial 6 finished with value: 0.815874429100629 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.8161187901167307.\u001b[0m\n",
      "feature_fraction, val_score: 0.816119: 100%|##########| 7/7 [00:27<00:00,  3.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's auc: 0.79583\tvalid_1's auc: 0.815874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:   5%|5         | 1/20 [00:03<01:03,  3.36s/it]\u001b[32m[I 2021-11-03 11:00:56,328]\u001b[0m Trial 7 finished with value: 0.8154538948271943 and parameters: {'num_leaves': 69}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:   5%|5         | 1/20 [00:03<01:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.804948\tvalid_1's auc: 0.815454\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  10%|#         | 2/20 [00:08<01:14,  4.15s/it]\u001b[32m[I 2021-11-03 11:01:01,042]\u001b[0m Trial 8 finished with value: 0.8137953301538743 and parameters: {'num_leaves': 201}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  10%|#         | 2/20 [00:08<01:14,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.846049\tvalid_1's auc: 0.813795\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  15%|#5        | 3/20 [00:11<01:06,  3.93s/it]\u001b[32m[I 2021-11-03 11:01:04,701]\u001b[0m Trial 9 finished with value: 0.8154538948271943 and parameters: {'num_leaves': 69}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  15%|#5        | 3/20 [00:11<01:06,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.804948\tvalid_1's auc: 0.815454\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  20%|##        | 4/20 [00:15<01:03,  3.96s/it]\u001b[32m[I 2021-11-03 11:01:08,701]\u001b[0m Trial 10 finished with value: 0.8147457222694642 and parameters: {'num_leaves': 88}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  20%|##        | 4/20 [00:15<01:03,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.819314\tvalid_1's auc: 0.814648\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.816795\tvalid_1's auc: 0.814746\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  25%|##5       | 5/20 [00:19<01:00,  4.04s/it]\u001b[32m[I 2021-11-03 11:01:12,883]\u001b[0m Trial 11 finished with value: 0.8147840232114574 and parameters: {'num_leaves': 131}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  25%|##5       | 5/20 [00:19<01:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.833379\tvalid_1's auc: 0.814784\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  30%|###       | 6/20 [00:23<00:56,  4.01s/it]\u001b[32m[I 2021-11-03 11:01:16,825]\u001b[0m Trial 12 finished with value: 0.8141742929938175 and parameters: {'num_leaves': 148}. Best is trial 7 with value: 0.8154538948271943.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  30%|###       | 6/20 [00:23<00:56,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.828162\tvalid_1's auc: 0.814174\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.798774\tvalid_1's auc: 0.815335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  35%|###5      | 7/20 [00:27<00:52,  4.03s/it]\u001b[32m[I 2021-11-03 11:01:20,911]\u001b[0m Trial 13 finished with value: 0.8154772231112335 and parameters: {'num_leaves': 50}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  35%|###5      | 7/20 [00:27<00:52,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.80171\tvalid_1's auc: 0.815477\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  40%|####      | 8/20 [00:31<00:48,  4.00s/it]\u001b[32m[I 2021-11-03 11:01:24,850]\u001b[0m Trial 14 finished with value: 0.8138903935840741 and parameters: {'num_leaves': 184}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  40%|####      | 8/20 [00:31<00:48,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.840158\tvalid_1's auc: 0.81389\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.79519\tvalid_1's auc: 0.815225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  45%|####5     | 9/20 [00:35<00:42,  3.82s/it]\u001b[32m[I 2021-11-03 11:01:28,278]\u001b[0m Trial 15 finished with value: 0.8153481475054377 and parameters: {'num_leaves': 44}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  45%|####5     | 9/20 [00:35<00:42,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.798042\tvalid_1's auc: 0.815348\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  50%|#####     | 10/20 [00:38<00:36,  3.62s/it]\u001b[32m[I 2021-11-03 11:01:31,451]\u001b[0m Trial 16 finished with value: 0.8147805300332616 and parameters: {'num_leaves': 90}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  50%|#####     | 10/20 [00:38<00:36,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.807562\tvalid_1's auc: 0.814781\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.747796\tvalid_1's auc: 0.793371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  55%|#####5    | 11/20 [00:41<00:31,  3.50s/it]\u001b[32m[I 2021-11-03 11:01:34,657]\u001b[0m Trial 17 finished with value: 0.7992102234924646 and parameters: {'num_leaves': 2}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  55%|#####5    | 11/20 [00:41<00:31,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.753724\tvalid_1's auc: 0.799179\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's auc: 0.75347\tvalid_1's auc: 0.79921\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.76261\tvalid_1's auc: 0.807799\n",
      "[200]\tvalid_0's auc: 0.768592\tvalid_1's auc: 0.812\n",
      "[300]\tvalid_0's auc: 0.772057\tvalid_1's auc: 0.813752\n",
      "[400]\tvalid_0's auc: 0.775095\tvalid_1's auc: 0.814591\n",
      "[500]\tvalid_0's auc: 0.777612\tvalid_1's auc: 0.815131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  60%|######    | 12/20 [00:50<00:41,  5.23s/it]\u001b[32m[I 2021-11-03 11:01:43,848]\u001b[0m Trial 18 finished with value: 0.8153020802186202 and parameters: {'num_leaves': 5}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  60%|######    | 12/20 [00:50<00:41,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[536]\tvalid_0's auc: 0.778432\tvalid_1's auc: 0.815302\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.79519\tvalid_1's auc: 0.815225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  65%|######5   | 13/20 [00:54<00:33,  4.71s/it]\u001b[32m[I 2021-11-03 11:01:47,383]\u001b[0m Trial 19 finished with value: 0.8153481475054377 and parameters: {'num_leaves': 44}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  65%|######5   | 13/20 [00:54<00:33,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.798042\tvalid_1's auc: 0.815348\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  70%|#######   | 14/20 [00:57<00:26,  4.37s/it]\u001b[32m[I 2021-11-03 11:01:50,942]\u001b[0m Trial 20 finished with value: 0.8122600188626943 and parameters: {'num_leaves': 253}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  70%|#######   | 14/20 [00:57<00:26,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.843521\tvalid_1's auc: 0.81226\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  75%|#######5  | 15/20 [01:01<00:19,  3.98s/it]\u001b[32m[I 2021-11-03 11:01:54,023]\u001b[0m Trial 21 finished with value: 0.815441003568373 and parameters: {'num_leaves': 41}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  75%|#######5  | 15/20 [01:01<00:19,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.793285\tvalid_1's auc: 0.815375\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.791918\tvalid_1's auc: 0.815441\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.827741\tvalid_1's auc: 0.814469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  80%|########  | 16/20 [01:04<00:15,  3.91s/it]\u001b[32m[I 2021-11-03 11:01:57,782]\u001b[0m Trial 22 finished with value: 0.8146823283196027 and parameters: {'num_leaves': 107}. Best is trial 13 with value: 0.8154772231112335.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  80%|########  | 16/20 [01:04<00:15,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.82613\tvalid_1's auc: 0.814682\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.779122\tvalid_1's auc: 0.814003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  85%|########5 | 17/20 [01:09<00:12,  4.25s/it]\u001b[32m[I 2021-11-03 11:02:02,806]\u001b[0m Trial 23 finished with value: 0.8155025017563488 and parameters: {'num_leaves': 20}. Best is trial 23 with value: 0.8155025017563488.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  85%|########5 | 17/20 [01:09<00:12,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's auc: 0.789661\tvalid_1's auc: 0.815503\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.759668\tvalid_1's auc: 0.805613\n",
      "[200]\tvalid_0's auc: 0.765379\tvalid_1's auc: 0.809811\n",
      "[300]\tvalid_0's auc: 0.768665\tvalid_1's auc: 0.811707\n",
      "[400]\tvalid_0's auc: 0.771165\tvalid_1's auc: 0.813063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  90%|######### | 18/20 [01:19<00:11,  5.74s/it]\u001b[32m[I 2021-11-03 11:02:12,015]\u001b[0m Trial 24 finished with value: 0.8140113292305864 and parameters: {'num_leaves': 4}. Best is trial 23 with value: 0.8155025017563488.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  90%|######### | 18/20 [01:19<00:11,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's auc: 0.773348\tvalid_1's auc: 0.814011\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's auc: 0.773348\tvalid_1's auc: 0.814011\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.785711\tvalid_1's auc: 0.81533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119:  95%|#########5| 19/20 [01:22<00:05,  5.04s/it]\u001b[32m[I 2021-11-03 11:02:15,436]\u001b[0m Trial 25 finished with value: 0.8157957033081403 and parameters: {'num_leaves': 30}. Best is trial 25 with value: 0.8157957033081403.\u001b[0m\n",
      "num_leaves, val_score: 0.816119:  95%|#########5| 19/20 [01:22<00:05,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.787912\tvalid_1's auc: 0.815796\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.779682\tvalid_1's auc: 0.814683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.816119: 100%|##########| 20/20 [01:26<00:00,  4.73s/it]\u001b[32m[I 2021-11-03 11:02:19,439]\u001b[0m Trial 26 finished with value: 0.8159160539633281 and parameters: {'num_leaves': 21}. Best is trial 26 with value: 0.8159160539633281.\u001b[0m\n",
      "num_leaves, val_score: 0.816119: 100%|##########| 20/20 [01:26<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's auc: 0.78643\tvalid_1's auc: 0.815916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786861\tvalid_1's auc: 0.814909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  10%|#         | 1/10 [00:04<00:38,  4.31s/it]\u001b[32m[I 2021-11-03 11:02:23,758]\u001b[0m Trial 27 finished with value: 0.8152100166239324 and parameters: {'bagging_fraction': 0.7819444662387276, 'bagging_freq': 6}. Best is trial 27 with value: 0.8152100166239324.\u001b[0m\n",
      "bagging, val_score: 0.816119:  10%|#         | 1/10 [00:04<00:38,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.79115\tvalid_1's auc: 0.81521\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78693\tvalid_1's auc: 0.814985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  20%|##        | 2/10 [00:08<00:34,  4.27s/it]\u001b[32m[I 2021-11-03 11:02:27,994]\u001b[0m Trial 28 finished with value: 0.815587772431776 and parameters: {'bagging_fraction': 0.8084076945512946, 'bagging_freq': 7}. Best is trial 28 with value: 0.815587772431776.\u001b[0m\n",
      "bagging, val_score: 0.816119:  20%|##        | 2/10 [00:08<00:34,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.791067\tvalid_1's auc: 0.815588\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786492\tvalid_1's auc: 0.814993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  30%|###       | 3/10 [00:13<00:30,  4.41s/it]\u001b[32m[I 2021-11-03 11:02:32,571]\u001b[0m Trial 29 finished with value: 0.8154329361480136 and parameters: {'bagging_fraction': 0.8534784634067414, 'bagging_freq': 7}. Best is trial 28 with value: 0.815587772431776.\u001b[0m\n",
      "bagging, val_score: 0.816119:  30%|###       | 3/10 [00:13<00:30,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.793996\tvalid_1's auc: 0.815433\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.787039\tvalid_1's auc: 0.815199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  40%|####      | 4/10 [00:17<00:26,  4.48s/it]\u001b[32m[I 2021-11-03 11:02:37,157]\u001b[0m Trial 30 finished with value: 0.8157577397111443 and parameters: {'bagging_fraction': 0.9277229089623277, 'bagging_freq': 7}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  40%|####      | 4/10 [00:17<00:26,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.792095\tvalid_1's auc: 0.815758\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78693\tvalid_1's auc: 0.81518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  50%|#####     | 5/10 [00:22<00:22,  4.43s/it]\u001b[32m[I 2021-11-03 11:02:41,512]\u001b[0m Trial 31 finished with value: 0.8154496684598718 and parameters: {'bagging_fraction': 0.8969340396851324, 'bagging_freq': 4}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  50%|#####     | 5/10 [00:22<00:22,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.790669\tvalid_1's auc: 0.81545\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006852 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.785795\tvalid_1's auc: 0.813791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  60%|######    | 6/10 [00:25<00:16,  4.10s/it]\u001b[32m[I 2021-11-03 11:02:44,968]\u001b[0m Trial 32 finished with value: 0.81393983588084 and parameters: {'bagging_fraction': 0.44459771064561715, 'bagging_freq': 2}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  60%|######    | 6/10 [00:25<00:16,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.786722\tvalid_1's auc: 0.81394\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786215\tvalid_1's auc: 0.814531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  70%|#######   | 7/10 [00:29<00:12,  4.19s/it]\u001b[32m[I 2021-11-03 11:02:49,336]\u001b[0m Trial 33 finished with value: 0.8150733193611666 and parameters: {'bagging_fraction': 0.6799101394611655, 'bagging_freq': 7}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  70%|#######   | 7/10 [00:29<00:12,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.790911\tvalid_1's auc: 0.815073\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786473\tvalid_1's auc: 0.814508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  80%|########  | 8/10 [00:33<00:08,  4.12s/it]\u001b[32m[I 2021-11-03 11:02:53,304]\u001b[0m Trial 34 finished with value: 0.8150935553810643 and parameters: {'bagging_fraction': 0.5403204834343622, 'bagging_freq': 1}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  80%|########  | 8/10 [00:33<00:08,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.79133\tvalid_1's auc: 0.815094\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007515 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78579\tvalid_1's auc: 0.813646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119:  90%|######### | 9/10 [00:38<00:04,  4.20s/it]\u001b[32m[I 2021-11-03 11:02:57,699]\u001b[0m Trial 35 finished with value: 0.8142624519664111 and parameters: {'bagging_fraction': 0.5667434210897084, 'bagging_freq': 5}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119:  90%|######### | 9/10 [00:38<00:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.792086\tvalid_1's auc: 0.814262\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.816119: 100%|##########| 10/10 [00:41<00:00,  3.95s/it]\u001b[32m[I 2021-11-03 11:03:01,078]\u001b[0m Trial 36 finished with value: 0.813627744179191 and parameters: {'bagging_fraction': 0.5410201933639907, 'bagging_freq': 7}. Best is trial 30 with value: 0.8157577397111443.\u001b[0m\n",
      "bagging, val_score: 0.816119: 100%|##########| 10/10 [00:41<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.783497\tvalid_1's auc: 0.813628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816119:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.787775\tvalid_1's auc: 0.815085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816119:  33%|###3      | 1/3 [00:04<00:08,  4.43s/it]\u001b[32m[I 2021-11-03 11:03:05,515]\u001b[0m Trial 37 finished with value: 0.815585838060463 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.815585838060463.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.816119:  33%|###3      | 1/3 [00:04<00:08,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.792485\tvalid_1's auc: 0.815586\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.787095\tvalid_1's auc: 0.815266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816119:  67%|######6   | 2/3 [00:08<00:04,  4.25s/it]\u001b[32m[I 2021-11-03 11:03:09,631]\u001b[0m Trial 38 finished with value: 0.8157370470080192 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.8157370470080192.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.816119:  67%|######6   | 2/3 [00:08<00:04,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.792576\tvalid_1's auc: 0.815737\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.787164\tvalid_1's auc: 0.815379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.816119: 100%|##########| 3/3 [00:12<00:00,  4.03s/it]\u001b[32m[I 2021-11-03 11:03:13,396]\u001b[0m Trial 39 finished with value: 0.8159464282728741 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.8159464282728741.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.816119: 100%|##########| 3/3 [00:12<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's auc: 0.792272\tvalid_1's auc: 0.815946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786351\tvalid_1's auc: 0.815276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:   5%|5         | 1/20 [00:03<01:14,  3.94s/it]\u001b[32m[I 2021-11-03 11:03:17,336]\u001b[0m Trial 40 finished with value: 0.8159124675765146 and parameters: {'lambda_l1': 6.850644918235034e-06, 'lambda_l2': 0.49689530809707694}. Best is trial 40 with value: 0.8159124675765146.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:   5%|5         | 1/20 [00:03<01:14,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.791876\tvalid_1's auc: 0.815912\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786715\tvalid_1's auc: 0.815559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:  10%|#         | 2/20 [00:07<01:11,  3.97s/it]\u001b[32m[I 2021-11-03 11:03:21,330]\u001b[0m Trial 41 finished with value: 0.816118520240733 and parameters: {'lambda_l1': 1.8332905750979925e-05, 'lambda_l2': 3.1801949340352274e-06}. Best is trial 41 with value: 0.816118520240733.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:  10%|#         | 2/20 [00:07<01:11,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.792783\tvalid_1's auc: 0.816119\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786711\tvalid_1's auc: 0.815533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:  15%|#5        | 3/20 [00:11<01:07,  3.95s/it]\u001b[32m[I 2021-11-03 11:03:25,256]\u001b[0m Trial 42 finished with value: 0.8158955543073401 and parameters: {'lambda_l1': 0.0001631570292608222, 'lambda_l2': 0.0050334530857878805}. Best is trial 41 with value: 0.816118520240733.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:  15%|#5        | 3/20 [00:11<01:07,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.791561\tvalid_1's auc: 0.815896\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78643\tvalid_1's auc: 0.815231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:  20%|##        | 4/20 [00:15<01:01,  3.82s/it]\u001b[32m[I 2021-11-03 11:03:28,882]\u001b[0m Trial 43 finished with value: 0.8157610094226542 and parameters: {'lambda_l1': 0.015792727845652024, 'lambda_l2': 7.832621945249258e-06}. Best is trial 41 with value: 0.816118520240733.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:  20%|##        | 4/20 [00:15<01:01,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.790163\tvalid_1's auc: 0.815761\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786715\tvalid_1's auc: 0.815558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:  25%|##5       | 5/20 [00:19<00:58,  3.88s/it]\u001b[32m[I 2021-11-03 11:03:32,865]\u001b[0m Trial 44 finished with value: 0.8161188306761292 and parameters: {'lambda_l1': 2.0401411516956983e-06, 'lambda_l2': 1.2806841045032802e-08}. Best is trial 44 with value: 0.8161188306761292.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:  25%|##5       | 5/20 [00:19<00:58,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.792783\tvalid_1's auc: 0.816119\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786725\tvalid_1's auc: 0.815265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816119:  30%|###       | 6/20 [00:23<00:54,  3.90s/it]\u001b[32m[I 2021-11-03 11:03:36,800]\u001b[0m Trial 45 finished with value: 0.8159569553867559 and parameters: {'lambda_l1': 2.023640487607731e-06, 'lambda_l2': 0.020341043853966796}. Best is trial 44 with value: 0.8161188306761292.\u001b[0m\n",
      "regularization_factors, val_score: 0.816119:  30%|###       | 6/20 [00:23<00:54,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.792473\tvalid_1's auc: 0.815957\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786432\tvalid_1's auc: 0.815383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816552:  35%|###5      | 7/20 [00:27<00:53,  4.12s/it]\u001b[32m[I 2021-11-03 11:03:41,382]\u001b[0m Trial 46 finished with value: 0.8165518174648918 and parameters: {'lambda_l1': 0.4264327025030825, 'lambda_l2': 0.05292576888031219}. Best is trial 46 with value: 0.8165518174648918.\u001b[0m\n",
      "regularization_factors, val_score: 0.816552:  35%|###5      | 7/20 [00:27<00:53,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.7961\tvalid_1's auc: 0.816552\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.784539\tvalid_1's auc: 0.815373\n",
      "[200]\tvalid_0's auc: 0.798666\tvalid_1's auc: 0.817057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  40%|####      | 8/20 [00:33<00:55,  4.66s/it]\u001b[32m[I 2021-11-03 11:03:47,190]\u001b[0m Trial 47 finished with value: 0.8171411381152076 and parameters: {'lambda_l1': 4.949852543152555, 'lambda_l2': 7.464915602283219e-06}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  40%|####      | 8/20 [00:33<00:55,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.799742\tvalid_1's auc: 0.817141\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786715\tvalid_1's auc: 0.815559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  45%|####5     | 9/20 [00:37<00:48,  4.45s/it]\u001b[32m[I 2021-11-03 11:03:51,191]\u001b[0m Trial 48 finished with value: 0.8161193735480784 and parameters: {'lambda_l1': 2.1853017415045607e-08, 'lambda_l2': 0.00011482957648802837}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  45%|####5     | 9/20 [00:37<00:48,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.792783\tvalid_1's auc: 0.816119\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786508\tvalid_1's auc: 0.815811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  50%|#####     | 10/20 [00:41<00:42,  4.21s/it]\u001b[32m[I 2021-11-03 11:03:54,865]\u001b[0m Trial 49 finished with value: 0.8160362068914482 and parameters: {'lambda_l1': 0.33427900416491346, 'lambda_l2': 7.004469598876842e-07}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  50%|#####     | 10/20 [00:41<00:42,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.789265\tvalid_1's auc: 0.816036\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.785289\tvalid_1's auc: 0.815494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  55%|#####5    | 11/20 [00:46<00:39,  4.42s/it]\u001b[32m[I 2021-11-03 11:03:59,770]\u001b[0m Trial 50 finished with value: 0.8168637484889235 and parameters: {'lambda_l1': 2.683279829113512, 'lambda_l2': 1.1085739888859234e-08}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  55%|#####5    | 11/20 [00:46<00:39,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's auc: 0.796929\tvalid_1's auc: 0.816864\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783256\tvalid_1's auc: 0.815267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  60%|######    | 12/20 [00:51<00:37,  4.64s/it]\u001b[32m[I 2021-11-03 11:04:04,913]\u001b[0m Trial 51 finished with value: 0.8168516922077194 and parameters: {'lambda_l1': 9.473820860236163, 'lambda_l2': 1.029639413564771e-08}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  60%|######    | 12/20 [00:51<00:37,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's auc: 0.793305\tvalid_1's auc: 0.816852\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783394\tvalid_1's auc: 0.815527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  65%|######5   | 13/20 [00:57<00:34,  4.92s/it]\u001b[32m[I 2021-11-03 11:04:10,469]\u001b[0m Trial 52 finished with value: 0.8170806890116739 and parameters: {'lambda_l1': 9.116241352856326, 'lambda_l2': 4.42613287932094e-08}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  65%|######5   | 13/20 [00:57<00:34,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's auc: 0.795\tvalid_1's auc: 0.817081\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786559\tvalid_1's auc: 0.815332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817141:  70%|#######   | 14/20 [01:00<00:27,  4.58s/it]\u001b[32m[I 2021-11-03 11:04:14,250]\u001b[0m Trial 53 finished with value: 0.8158723395116179 and parameters: {'lambda_l1': 0.01116719983039751, 'lambda_l2': 2.0305926410497284e-07}. Best is trial 47 with value: 0.8171411381152076.\u001b[0m\n",
      "regularization_factors, val_score: 0.817141:  70%|#######   | 14/20 [01:00<00:27,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.789892\tvalid_1's auc: 0.815872\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783584\tvalid_1's auc: 0.815507\n",
      "[200]\tvalid_0's auc: 0.795978\tvalid_1's auc: 0.817084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173:  75%|#######5  | 15/20 [01:06<00:25,  5.02s/it]\u001b[32m[I 2021-11-03 11:04:20,295]\u001b[0m Trial 54 finished with value: 0.8171728774045108 and parameters: {'lambda_l1': 9.327802059899733, 'lambda_l2': 0.00010111708372666778}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173:  75%|#######5  | 15/20 [01:06<00:25,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's auc: 0.797524\tvalid_1's auc: 0.817173\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786558\tvalid_1's auc: 0.815334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173:  80%|########  | 16/20 [01:11<00:19,  4.82s/it]\u001b[32m[I 2021-11-03 11:04:24,644]\u001b[0m Trial 55 finished with value: 0.8159211402678977 and parameters: {'lambda_l1': 0.012949974547951415, 'lambda_l2': 0.00016510952612418294}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173:  80%|########  | 16/20 [01:11<00:19,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's auc: 0.795212\tvalid_1's auc: 0.815921\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786411\tvalid_1's auc: 0.815405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173:  85%|########5 | 17/20 [01:15<00:13,  4.61s/it]\u001b[32m[I 2021-11-03 11:04:28,762]\u001b[0m Trial 56 finished with value: 0.8161522153510311 and parameters: {'lambda_l1': 0.264186280536142, 'lambda_l2': 1.6350148523949454e-05}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173:  85%|########5 | 17/20 [01:15<00:13,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.79279\tvalid_1's auc: 0.816152\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786714\tvalid_1's auc: 0.81556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173:  90%|######### | 18/20 [01:19<00:09,  4.58s/it]\u001b[32m[I 2021-11-03 11:04:33,288]\u001b[0m Trial 57 finished with value: 0.816411143821096 and parameters: {'lambda_l1': 1.0169651850013594e-08, 'lambda_l2': 0.001360051125275011}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173:  90%|######### | 18/20 [01:19<00:09,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's auc: 0.79773\tvalid_1's auc: 0.816411\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786714\tvalid_1's auc: 0.815558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173:  95%|#########5| 19/20 [01:24<00:04,  4.51s/it]\u001b[32m[I 2021-11-03 11:04:37,630]\u001b[0m Trial 58 finished with value: 0.8162764749182493 and parameters: {'lambda_l1': 0.001767473704974146, 'lambda_l2': 3.397591822602715e-05}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173:  95%|#########5| 19/20 [01:24<00:04,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.795362\tvalid_1's auc: 0.816276\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.786009\tvalid_1's auc: 0.815438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.817173: 100%|##########| 20/20 [01:28<00:00,  4.57s/it]\u001b[32m[I 2021-11-03 11:04:42,354]\u001b[0m Trial 59 finished with value: 0.8162728003927429 and parameters: {'lambda_l1': 1.0608359515895178, 'lambda_l2': 1.6952078657028416e-06}. Best is trial 54 with value: 0.8171728774045108.\u001b[0m\n",
      "regularization_factors, val_score: 0.817173: 100%|##########| 20/20 [01:28<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's auc: 0.797787\tvalid_1's auc: 0.816273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817173:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783421\tvalid_1's auc: 0.815476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817173:  20%|##        | 1/5 [00:05<00:20,  5.20s/it]\u001b[32m[I 2021-11-03 11:04:47,558]\u001b[0m Trial 60 finished with value: 0.8171182665143958 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.8171182665143958.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817173:  20%|##        | 1/5 [00:05<00:20,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.795953\tvalid_1's auc: 0.817091\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's auc: 0.795006\tvalid_1's auc: 0.817118\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783584\tvalid_1's auc: 0.815507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817173:  40%|####      | 2/5 [00:10<00:15,  5.01s/it]\u001b[32m[I 2021-11-03 11:04:52,442]\u001b[0m Trial 61 finished with value: 0.8169525798115461 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.8171182665143958.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817173:  40%|####      | 2/5 [00:10<00:15,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.793366\tvalid_1's auc: 0.816953\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783293\tvalid_1's auc: 0.815657\n",
      "[200]\tvalid_0's auc: 0.79628\tvalid_1's auc: 0.817603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817682:  60%|######    | 3/5 [00:15<00:10,  5.30s/it]\u001b[32m[I 2021-11-03 11:04:58,074]\u001b[0m Trial 62 finished with value: 0.8176815047415166 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.8176815047415166.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817682:  60%|######    | 3/5 [00:15<00:10,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's auc: 0.797052\tvalid_1's auc: 0.817682\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783584\tvalid_1's auc: 0.815507\n",
      "[200]\tvalid_0's auc: 0.796036\tvalid_1's auc: 0.817099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817682:  80%|########  | 4/5 [00:22<00:05,  5.91s/it]\u001b[32m[I 2021-11-03 11:05:04,929]\u001b[0m Trial 63 finished with value: 0.8173418798381878 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.8176815047415166.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817682:  80%|########  | 4/5 [00:22<00:05,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's auc: 0.799337\tvalid_1's auc: 0.817342\n",
      "[LightGBM] [Info] Number of positive: 173288, number of negative: 40822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4991\n",
      "[LightGBM] [Info] Number of data points in the train set: 214110, number of used features: 68\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809341 -> initscore=1.445734\n",
      "[LightGBM] [Info] Start training from score 1.445734\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783269\tvalid_1's auc: 0.815676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817682: 100%|##########| 5/5 [00:28<00:00,  5.75s/it]\u001b[32m[I 2021-11-03 11:05:10,379]\u001b[0m Trial 64 finished with value: 0.8173598952310177 and parameters: {'min_child_samples': 25}. Best is trial 62 with value: 0.8176815047415166.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817682: 100%|##########| 5/5 [00:28<00:00,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's auc: 0.793674\tvalid_1's auc: 0.81736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_clf_o = lgb_o.train(params, lgb_train,\n",
    "                        valid_sets=(lgb_train, lgb_valid),\n",
    "                        verbose_eval=100,\n",
    "                        early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d37cb1c-9e1e-4f3b-81f2-9b1fdccabae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'random_state': 100,\n",
       " 'metric': 'auc',\n",
       " 'boosting': 'gbdt',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 9.327802059899733,\n",
       " 'lambda_l2': 0.00010111708372666778,\n",
       " 'num_leaves': 31,\n",
       " 'feature_fraction': 0.4,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 50,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf_o.params#確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dbfcfa7-6762-438f-ba15-7d1cc972c44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(r.data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d2d459e-ab36-4a88-b021-8331d4a8f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数と目的変数に分ける。dateはこの後不要なので省く。\n",
    "X_train = train.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_test = test['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324e0d21-936c-472b-a8b8-c3c93e4173c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf_o.params2={\n",
    "'objective': 'binary',\n",
    " 'random_state': 100,\n",
    " 'metric': 'auc',\n",
    " 'boosting': 'gbdt',\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 9.327802059899733,\n",
    " 'lambda_l2': 0.00010111708372666778,\n",
    " 'num_leaves': 31,\n",
    " 'feature_fraction': 0.4,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 0,\n",
    " 'min_child_samples': 50,\n",
    " 'num_iterations': 1000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca8c5050-f8e2-4739-975d-64467f5bf9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00010111708372666778, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00010111708372666778\n",
      "[LightGBM] [Warning] lambda_l1 is set=9.327802059899733, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.327802059899733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting='gbdt',\n",
       "               feature_fraction=0.4, feature_pre_filter=False,\n",
       "               lambda_l1=9.327802059899733, lambda_l2=0.00010111708372666778,\n",
       "               metric='auc', min_child_samples=50, num_iterations=1000,\n",
       "               objective='binary', random_state=100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(**lgb_clf_o.params2)\n",
    "lgb_clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9dbf50-efd7-4357-b30c-3f7e4cdcd370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率(test) 0.8185615070683606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('正解率(test)',accuracy_score(y_test, lgb_clf.predict(X_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6ea6bd-b7cb-4eaa-b54c-230ee1e486c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: axis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6275930673902916"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lgb_clf.predict(X_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fedc35c-6210-407a-9d14-64ad42ab92c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
