{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4efd120e-3678-48a5-b016-e1a3bc4cacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#親クラスの読み込み\n",
    "from DP import DataProcessor\n",
    "from Result import Results\n",
    "from HR import HorseResults\n",
    "from Ped import Peds\n",
    "from ST import ShutubaTable\n",
    "from JR import JockeyResults\n",
    "from TR import TrainerResults\n",
    "import update_data\n",
    "import pickle\n",
    "import bz2\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b65922-6035-4b06-9d90-ff54bb7d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリをインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "import warnings\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a34930-c1a7-454b-a192-80a317b6c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Results.read_pickle(['data/race_results_all.pickle'])\n",
    "hr = HorseResults.read_pickle(['data/horse_results_all.pickle'])\n",
    "p = Peds.read_pickle(['data/peds_all.pickle'])\n",
    "jr = JockeyResults.read_pickle(['data/jockey_results.pickle'])\n",
    "tr = TrainerResults.read_pickle(['data/trainer_results.pickle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10a2f26-8f89-4012-b0ca-30f099dafb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11abcd3a-5bc9-41e8-bf7b-95adfe86bbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>prize</th>\n",
       "      <th>race_turn</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>race_condition</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>race_park</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>牝</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  frame_number  horse_number sex  age  \\\n",
       "201101010101     1   4.7       3.0             2             2   牡    2   \n",
       "201101010101     2   3.4       2.0             3             3   牡    2   \n",
       "201101010101     3   2.1       1.0             5             5   牡    2   \n",
       "201101010101     4   7.0       4.0             4             4   牡    2   \n",
       "201101010101     5  17.5       5.0             1             1   牝    2   \n",
       "\n",
       "              weight_j  prize race_turn  course_len weather race_type  \\\n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "\n",
       "             race_condition  n_horses       date race_park    horse_id  \\\n",
       "201101010101              良         7 2011-08-13        札幌  2009105006   \n",
       "201101010101              良         7 2011-08-13        札幌  2009100577   \n",
       "201101010101              良         7 2011-08-13        札幌  2009102908   \n",
       "201101010101              良         7 2011-08-13        札幌  2009109159   \n",
       "201101010101              良         7 2011-08-13        札幌  2009105263   \n",
       "\n",
       "             jockey_id trainer_id  \n",
       "201101010101     01019      00379  \n",
       "201101010101     05203      01061  \n",
       "201101010101     01093      01089  \n",
       "201101010101     01095      01075  \n",
       "201101010101     01127      01026  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d211e935-5f1c-4b9f-a6d6-0de15b5c08db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad7eb8fcce64f25acdacda44e986a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_horse_results(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230a8262-2627-4b43-ab0d-0972920cb237",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.encode()\n",
    "r.merge_peds(p.peds_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373fcf1f-613d-4a37-8815-7bdb13d88450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d412187d9d4a8d9a6e83d6eea651c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_jockey(jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e26df23-725c-4e00-8532-fe4db76391cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71e9583546541cca011287b5ddec161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1154 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r.merge_trainer(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9388f2-e658-4552-b46b-4896f795e790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>prize</th>\n",
       "      <th>race_turn</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>race_condition</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>race_park</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>rank_1R_before</th>\n",
       "      <th>money_1R_before</th>\n",
       "      <th>favorite_1R_before</th>\n",
       "      <th>last_1R_before</th>\n",
       "      <th>odds_1R_before</th>\n",
       "      <th>final_corner_1R_before</th>\n",
       "      <th>rank_2R_before</th>\n",
       "      <th>money_2R_before</th>\n",
       "      <th>favorite_2R_before</th>\n",
       "      <th>last_2R_before</th>\n",
       "      <th>odds_2R_before</th>\n",
       "      <th>final_corner_2R_before</th>\n",
       "      <th>rank_3R_before</th>\n",
       "      <th>money_3R_before</th>\n",
       "      <th>favorite_3R_before</th>\n",
       "      <th>last_3R_before</th>\n",
       "      <th>odds_3R_before</th>\n",
       "      <th>final_corner_3R_before</th>\n",
       "      <th>course_len_all</th>\n",
       "      <th>time_rank_p</th>\n",
       "      <th>interval</th>\n",
       "      <th>course_len_dif</th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>win_rate_1_1Y_before_j</th>\n",
       "      <th>win_rate_3_1Y_before_j</th>\n",
       "      <th>prize_1Y_before_j</th>\n",
       "      <th>win_rate_1_1Y_before_t</th>\n",
       "      <th>win_rate_3_1Y_before_t</th>\n",
       "      <th>prize_1Y_before_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>779</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.240</td>\n",
       "      <td>96905.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.140</td>\n",
       "      <td>16330.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.333</td>\n",
       "      <td>188832.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.400</td>\n",
       "      <td>52106.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>789</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.262</td>\n",
       "      <td>137964.6</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.168</td>\n",
       "      <td>23638.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.194</td>\n",
       "      <td>95243.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.292</td>\n",
       "      <td>108027.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>牝</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>右</td>\n",
       "      <td>18</td>\n",
       "      <td>晴</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>札幌</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>969</td>\n",
       "      <td>1891</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>114614.3</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.167</td>\n",
       "      <td>23687.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  frame_number  horse_number sex  age  \\\n",
       "201101010101     1   4.7       3.0             2             2   牡    2   \n",
       "201101010101     2   3.4       2.0             3             3   牡    2   \n",
       "201101010101     3   2.1       1.0             5             5   牡    2   \n",
       "201101010101     4   7.0       4.0             4             4   牡    2   \n",
       "201101010101     5  17.5       5.0             1             1   牝    2   \n",
       "\n",
       "              weight_j  prize race_turn  course_len weather race_type  \\\n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "201101010101      54.0  500.0         右          18       晴         芝   \n",
       "\n",
       "             race_condition  n_horses       date race_park    horse_id  \\\n",
       "201101010101              良         7 2011-08-13        札幌  2009105006   \n",
       "201101010101              良         7 2011-08-13        札幌  2009100577   \n",
       "201101010101              良         7 2011-08-13        札幌  2009102908   \n",
       "201101010101              良         7 2011-08-13        札幌  2009109159   \n",
       "201101010101              良         7 2011-08-13        札幌  2009105263   \n",
       "\n",
       "             jockey_id trainer_id  rank_1R_before  money_1R_before  \\\n",
       "201101010101     01019      00379             8.0              0.0   \n",
       "201101010101     05203      01061             NaN              NaN   \n",
       "201101010101     01093      01089             NaN              NaN   \n",
       "201101010101     01095      01075             NaN              NaN   \n",
       "201101010101     01127      01026             NaN              NaN   \n",
       "\n",
       "              favorite_1R_before  last_1R_before  odds_1R_before  \\\n",
       "201101010101                 8.0            34.7            28.8   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "\n",
       "              final_corner_1R_before  rank_2R_before  money_2R_before  \\\n",
       "201101010101                    10.0             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "\n",
       "              favorite_2R_before  last_2R_before  odds_2R_before  \\\n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "\n",
       "              final_corner_2R_before  rank_3R_before  money_3R_before  \\\n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "201101010101                     NaN             NaN              NaN   \n",
       "\n",
       "              favorite_3R_before  last_3R_before  odds_3R_before  \\\n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "201101010101                 NaN             NaN             NaN   \n",
       "\n",
       "              final_corner_3R_before  course_len_all  time_rank_p  interval  \\\n",
       "201101010101                     NaN            14.0          1.0      34.0   \n",
       "201101010101                     NaN             NaN          NaN       NaN   \n",
       "201101010101                     NaN             NaN          NaN       NaN   \n",
       "201101010101                     NaN             NaN          NaN       NaN   \n",
       "201101010101                     NaN             NaN          NaN       NaN   \n",
       "\n",
       "              course_len_dif peds_0 peds_4  win_rate_1_1Y_before_j  \\\n",
       "201101010101             4.0    779   1457                   0.084   \n",
       "201101010101             NaN    763   1637                   0.119   \n",
       "201101010101             NaN    789   1457                   0.086   \n",
       "201101010101             NaN    779   1642                   0.069   \n",
       "201101010101             NaN    969   1891                   0.110   \n",
       "\n",
       "              win_rate_3_1Y_before_j  prize_1Y_before_j  \\\n",
       "201101010101                   0.240            96905.1   \n",
       "201101010101                   0.333           188832.6   \n",
       "201101010101                   0.262           137964.6   \n",
       "201101010101                   0.194            95243.0   \n",
       "201101010101                   0.284           114614.3   \n",
       "\n",
       "              win_rate_1_1Y_before_t  win_rate_3_1Y_before_t  \\\n",
       "201101010101                   0.062                   0.140   \n",
       "201101010101                   0.138                   0.400   \n",
       "201101010101                   0.051                   0.168   \n",
       "201101010101                   0.087                   0.292   \n",
       "201101010101                   0.062                   0.167   \n",
       "\n",
       "              prize_1Y_before_t  \n",
       "201101010101            16330.6  \n",
       "201101010101            52106.2  \n",
       "201101010101            23638.6  \n",
       "201101010101           108027.3  \n",
       "201101010101            23687.4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c384fd2-2bab-47a3-8925-ae4de6cc9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.process_categorical() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01962737-3326-4004-a712-088b70768751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>prize</th>\n",
       "      <th>course_len</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>rank_1R_before</th>\n",
       "      <th>money_1R_before</th>\n",
       "      <th>favorite_1R_before</th>\n",
       "      <th>last_1R_before</th>\n",
       "      <th>odds_1R_before</th>\n",
       "      <th>final_corner_1R_before</th>\n",
       "      <th>rank_2R_before</th>\n",
       "      <th>money_2R_before</th>\n",
       "      <th>favorite_2R_before</th>\n",
       "      <th>last_2R_before</th>\n",
       "      <th>odds_2R_before</th>\n",
       "      <th>final_corner_2R_before</th>\n",
       "      <th>rank_3R_before</th>\n",
       "      <th>money_3R_before</th>\n",
       "      <th>favorite_3R_before</th>\n",
       "      <th>last_3R_before</th>\n",
       "      <th>odds_3R_before</th>\n",
       "      <th>final_corner_3R_before</th>\n",
       "      <th>course_len_all</th>\n",
       "      <th>time_rank_p</th>\n",
       "      <th>interval</th>\n",
       "      <th>course_len_dif</th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>win_rate_1_1Y_before_j</th>\n",
       "      <th>win_rate_3_1Y_before_j</th>\n",
       "      <th>prize_1Y_before_j</th>\n",
       "      <th>win_rate_1_1Y_before_t</th>\n",
       "      <th>win_rate_3_1Y_before_t</th>\n",
       "      <th>prize_1Y_before_t</th>\n",
       "      <th>race_turn_右</th>\n",
       "      <th>race_turn_左</th>\n",
       "      <th>race_turn_直</th>\n",
       "      <th>race_turn_芝</th>\n",
       "      <th>race_turn_ー</th>\n",
       "      <th>weather_晴</th>\n",
       "      <th>weather_曇</th>\n",
       "      <th>weather_雨</th>\n",
       "      <th>weather_小雨</th>\n",
       "      <th>weather_雪</th>\n",
       "      <th>weather_小雪</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>race_condition_良</th>\n",
       "      <th>race_condition_稍重</th>\n",
       "      <th>race_condition_重</th>\n",
       "      <th>race_condition_不良</th>\n",
       "      <th>sex_牡</th>\n",
       "      <th>sex_牝</th>\n",
       "      <th>sex_セ</th>\n",
       "      <th>race_park_札幌</th>\n",
       "      <th>race_park_新潟</th>\n",
       "      <th>race_park_小倉</th>\n",
       "      <th>race_park_中山</th>\n",
       "      <th>race_park_阪神</th>\n",
       "      <th>race_park_函館</th>\n",
       "      <th>race_park_京都</th>\n",
       "      <th>race_park_東京</th>\n",
       "      <th>race_park_中京</th>\n",
       "      <th>race_park_福島</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>779</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.240</td>\n",
       "      <td>96905.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.140</td>\n",
       "      <td>16330.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.333</td>\n",
       "      <td>188832.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.400</td>\n",
       "      <td>52106.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>789</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.262</td>\n",
       "      <td>137964.6</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.168</td>\n",
       "      <td>23638.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.194</td>\n",
       "      <td>95243.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.292</td>\n",
       "      <td>108027.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>969</td>\n",
       "      <td>1891</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>114614.3</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.167</td>\n",
       "      <td>23687.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  frame_number  horse_number  age  weight_j  \\\n",
       "201101010101     1   4.7       3.0             2             2    2      54.0   \n",
       "201101010101     2   3.4       2.0             3             3    2      54.0   \n",
       "201101010101     3   2.1       1.0             5             5    2      54.0   \n",
       "201101010101     4   7.0       4.0             4             4    2      54.0   \n",
       "201101010101     5  17.5       5.0             1             1    2      54.0   \n",
       "\n",
       "              prize  course_len  n_horses       date    horse_id jockey_id  \\\n",
       "201101010101  500.0          18         7 2011-08-13  2009105006     01019   \n",
       "201101010101  500.0          18         7 2011-08-13  2009100577     05203   \n",
       "201101010101  500.0          18         7 2011-08-13  2009102908     01093   \n",
       "201101010101  500.0          18         7 2011-08-13  2009109159     01095   \n",
       "201101010101  500.0          18         7 2011-08-13  2009105263     01127   \n",
       "\n",
       "             trainer_id  rank_1R_before  money_1R_before  favorite_1R_before  \\\n",
       "201101010101      00379             8.0              0.0                 8.0   \n",
       "201101010101      01061             NaN              NaN                 NaN   \n",
       "201101010101      01089             NaN              NaN                 NaN   \n",
       "201101010101      01075             NaN              NaN                 NaN   \n",
       "201101010101      01026             NaN              NaN                 NaN   \n",
       "\n",
       "              last_1R_before  odds_1R_before  final_corner_1R_before  \\\n",
       "201101010101            34.7            28.8                    10.0   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_2R_before  money_2R_before  favorite_2R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_2R_before  odds_2R_before  final_corner_2R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_3R_before  money_3R_before  favorite_3R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_3R_before  odds_3R_before  final_corner_3R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              course_len_all  time_rank_p  interval  course_len_dif peds_0  \\\n",
       "201101010101            14.0          1.0      34.0             4.0    779   \n",
       "201101010101             NaN          NaN       NaN             NaN    763   \n",
       "201101010101             NaN          NaN       NaN             NaN    789   \n",
       "201101010101             NaN          NaN       NaN             NaN    779   \n",
       "201101010101             NaN          NaN       NaN             NaN    969   \n",
       "\n",
       "             peds_4  win_rate_1_1Y_before_j  win_rate_3_1Y_before_j  \\\n",
       "201101010101   1457                   0.084                   0.240   \n",
       "201101010101   1637                   0.119                   0.333   \n",
       "201101010101   1457                   0.086                   0.262   \n",
       "201101010101   1642                   0.069                   0.194   \n",
       "201101010101   1891                   0.110                   0.284   \n",
       "\n",
       "              prize_1Y_before_j  win_rate_1_1Y_before_t  \\\n",
       "201101010101            96905.1                   0.062   \n",
       "201101010101           188832.6                   0.138   \n",
       "201101010101           137964.6                   0.051   \n",
       "201101010101            95243.0                   0.087   \n",
       "201101010101           114614.3                   0.062   \n",
       "\n",
       "              win_rate_3_1Y_before_t  prize_1Y_before_t  race_turn_右  \\\n",
       "201101010101                   0.140            16330.6            1   \n",
       "201101010101                   0.400            52106.2            1   \n",
       "201101010101                   0.168            23638.6            1   \n",
       "201101010101                   0.292           108027.3            1   \n",
       "201101010101                   0.167            23687.4            1   \n",
       "\n",
       "              race_turn_左  race_turn_直  race_turn_芝  race_turn_ー  weather_晴  \\\n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "\n",
       "              weather_曇  weather_雨  weather_小雨  weather_雪  weather_小雪  \\\n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "\n",
       "              race_type_芝  race_type_ダート  race_type_障害  race_condition_良  \\\n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "\n",
       "              race_condition_稍重  race_condition_重  race_condition_不良  sex_牡  \\\n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      0   \n",
       "\n",
       "              sex_牝  sex_セ  race_park_札幌  race_park_新潟  race_park_小倉  \\\n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      1      0             1             0             0   \n",
       "\n",
       "              race_park_中山  race_park_阪神  race_park_函館  race_park_京都  \\\n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "\n",
       "              race_park_東京  race_park_中京  race_park_福島  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d7610d-b3b1-4ae2-89ef-b83f3b678b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_e = r.data_c[((r.data_c[\"rank\"]==0) & (r.data_c[\"odds\"]<=32.0)) | (r.data_c[\"rank\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e53e04e7-9eb3-4149-b1d3-eca46c911b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d = r.data_e[((r.data_e[\"rank\"]==0) & (r.data_e[\"favorite\"]<=10)) | (r.data_e[\"rank\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6757dbf9-dddc-4eb6-8fba-7d7c9c269d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_e = r.data_c[((r.data_c[\"rank\"]<=3) & (r.data_c[\"odds\"]<=32.0)) | (r.data_c[\"rank\"]>3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53e1ed87-aa9e-4efc-b1bc-166acbd29f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d = r.data_e[((r.data_e[\"rank\"]<=3) & (r.data_e[\"favorite\"]<=10)) | (r.data_e[\"rank\"]>3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f30075c1-1058-4ff0-aee1-4ae0846ea3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>frame_number</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>prize</th>\n",
       "      <th>course_len</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>rank_1R_before</th>\n",
       "      <th>money_1R_before</th>\n",
       "      <th>favorite_1R_before</th>\n",
       "      <th>last_1R_before</th>\n",
       "      <th>odds_1R_before</th>\n",
       "      <th>final_corner_1R_before</th>\n",
       "      <th>rank_2R_before</th>\n",
       "      <th>money_2R_before</th>\n",
       "      <th>favorite_2R_before</th>\n",
       "      <th>last_2R_before</th>\n",
       "      <th>odds_2R_before</th>\n",
       "      <th>final_corner_2R_before</th>\n",
       "      <th>rank_3R_before</th>\n",
       "      <th>money_3R_before</th>\n",
       "      <th>favorite_3R_before</th>\n",
       "      <th>last_3R_before</th>\n",
       "      <th>odds_3R_before</th>\n",
       "      <th>final_corner_3R_before</th>\n",
       "      <th>course_len_all</th>\n",
       "      <th>time_rank_p</th>\n",
       "      <th>interval</th>\n",
       "      <th>course_len_dif</th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>win_rate_1_1Y_before_j</th>\n",
       "      <th>win_rate_3_1Y_before_j</th>\n",
       "      <th>prize_1Y_before_j</th>\n",
       "      <th>win_rate_1_1Y_before_t</th>\n",
       "      <th>win_rate_3_1Y_before_t</th>\n",
       "      <th>prize_1Y_before_t</th>\n",
       "      <th>race_turn_右</th>\n",
       "      <th>race_turn_左</th>\n",
       "      <th>race_turn_直</th>\n",
       "      <th>race_turn_芝</th>\n",
       "      <th>race_turn_ー</th>\n",
       "      <th>weather_晴</th>\n",
       "      <th>weather_曇</th>\n",
       "      <th>weather_雨</th>\n",
       "      <th>weather_小雨</th>\n",
       "      <th>weather_雪</th>\n",
       "      <th>weather_小雪</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>race_condition_良</th>\n",
       "      <th>race_condition_稍重</th>\n",
       "      <th>race_condition_重</th>\n",
       "      <th>race_condition_不良</th>\n",
       "      <th>sex_牡</th>\n",
       "      <th>sex_牝</th>\n",
       "      <th>sex_セ</th>\n",
       "      <th>race_park_札幌</th>\n",
       "      <th>race_park_新潟</th>\n",
       "      <th>race_park_小倉</th>\n",
       "      <th>race_park_中山</th>\n",
       "      <th>race_park_阪神</th>\n",
       "      <th>race_park_函館</th>\n",
       "      <th>race_park_京都</th>\n",
       "      <th>race_park_東京</th>\n",
       "      <th>race_park_中京</th>\n",
       "      <th>race_park_福島</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>779</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.240</td>\n",
       "      <td>96905.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.140</td>\n",
       "      <td>16330.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.333</td>\n",
       "      <td>188832.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.400</td>\n",
       "      <td>52106.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>789</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.262</td>\n",
       "      <td>137964.6</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.168</td>\n",
       "      <td>23638.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.194</td>\n",
       "      <td>95243.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.292</td>\n",
       "      <td>108027.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>969</td>\n",
       "      <td>1891</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>114614.3</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.167</td>\n",
       "      <td>23687.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  frame_number  horse_number  age  weight_j  \\\n",
       "201101010101     1   4.7       3.0             2             2    2      54.0   \n",
       "201101010101     2   3.4       2.0             3             3    2      54.0   \n",
       "201101010101     3   2.1       1.0             5             5    2      54.0   \n",
       "201101010101     4   7.0       4.0             4             4    2      54.0   \n",
       "201101010101     5  17.5       5.0             1             1    2      54.0   \n",
       "\n",
       "              prize  course_len  n_horses       date    horse_id jockey_id  \\\n",
       "201101010101  500.0          18         7 2011-08-13  2009105006     01019   \n",
       "201101010101  500.0          18         7 2011-08-13  2009100577     05203   \n",
       "201101010101  500.0          18         7 2011-08-13  2009102908     01093   \n",
       "201101010101  500.0          18         7 2011-08-13  2009109159     01095   \n",
       "201101010101  500.0          18         7 2011-08-13  2009105263     01127   \n",
       "\n",
       "             trainer_id  rank_1R_before  money_1R_before  favorite_1R_before  \\\n",
       "201101010101      00379             8.0              0.0                 8.0   \n",
       "201101010101      01061             NaN              NaN                 NaN   \n",
       "201101010101      01089             NaN              NaN                 NaN   \n",
       "201101010101      01075             NaN              NaN                 NaN   \n",
       "201101010101      01026             NaN              NaN                 NaN   \n",
       "\n",
       "              last_1R_before  odds_1R_before  final_corner_1R_before  \\\n",
       "201101010101            34.7            28.8                    10.0   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_2R_before  money_2R_before  favorite_2R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_2R_before  odds_2R_before  final_corner_2R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              rank_3R_before  money_3R_before  favorite_3R_before  \\\n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "201101010101             NaN              NaN                 NaN   \n",
       "\n",
       "              last_3R_before  odds_3R_before  final_corner_3R_before  \\\n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "201101010101             NaN             NaN                     NaN   \n",
       "\n",
       "              course_len_all  time_rank_p  interval  course_len_dif peds_0  \\\n",
       "201101010101            14.0          1.0      34.0             4.0    779   \n",
       "201101010101             NaN          NaN       NaN             NaN    763   \n",
       "201101010101             NaN          NaN       NaN             NaN    789   \n",
       "201101010101             NaN          NaN       NaN             NaN    779   \n",
       "201101010101             NaN          NaN       NaN             NaN    969   \n",
       "\n",
       "             peds_4  win_rate_1_1Y_before_j  win_rate_3_1Y_before_j  \\\n",
       "201101010101   1457                   0.084                   0.240   \n",
       "201101010101   1637                   0.119                   0.333   \n",
       "201101010101   1457                   0.086                   0.262   \n",
       "201101010101   1642                   0.069                   0.194   \n",
       "201101010101   1891                   0.110                   0.284   \n",
       "\n",
       "              prize_1Y_before_j  win_rate_1_1Y_before_t  \\\n",
       "201101010101            96905.1                   0.062   \n",
       "201101010101           188832.6                   0.138   \n",
       "201101010101           137964.6                   0.051   \n",
       "201101010101            95243.0                   0.087   \n",
       "201101010101           114614.3                   0.062   \n",
       "\n",
       "              win_rate_3_1Y_before_t  prize_1Y_before_t  race_turn_右  \\\n",
       "201101010101                   0.140            16330.6            1   \n",
       "201101010101                   0.400            52106.2            1   \n",
       "201101010101                   0.168            23638.6            1   \n",
       "201101010101                   0.292           108027.3            1   \n",
       "201101010101                   0.167            23687.4            1   \n",
       "\n",
       "              race_turn_左  race_turn_直  race_turn_芝  race_turn_ー  weather_晴  \\\n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "\n",
       "              weather_曇  weather_雨  weather_小雨  weather_雪  weather_小雪  \\\n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "\n",
       "              race_type_芝  race_type_ダート  race_type_障害  race_condition_良  \\\n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "\n",
       "              race_condition_稍重  race_condition_重  race_condition_不良  sex_牡  \\\n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      0   \n",
       "\n",
       "              sex_牝  sex_セ  race_park_札幌  race_park_新潟  race_park_小倉  \\\n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      1      0             1             0             0   \n",
       "\n",
       "              race_park_中山  race_park_阪神  race_park_函館  race_park_京都  \\\n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "\n",
       "              race_park_東京  race_park_中京  race_park_福島  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  \n",
       "201101010101             0             0             0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e475b577-2826-41ee-9caf-e92c6a326da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_moeny = r.data_d[[\"money_1R_before\",\"money_2R_before\",\"money_3R_before\"]]\n",
    "df_money = df_tmp_moeny.mean(axis='columns') \n",
    "r.data_d[\"money_ave\"] = df_money\n",
    "r.data_d[\"money_rank\"]=r.data_d.groupby(level=0)[\"money_ave\"].rank(ascending=False,method=\"max\")\n",
    "r.data_d.drop([\"money_1R_before\",\"money_2R_before\",\"money_3R_before\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3459688c-17c2-4e1d-bb96-d565424c5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d.drop([\"favorite_1R_before\",\"favorite_2R_before\",\"favorite_3R_before\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e506209-9815-42f1-8ba6-8ff4f3073807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_final = r.data_d[[\"final_corner_1R_before\",\"final_corner_2R_before\",\"final_corner_3R_before\"]]\n",
    "df_final = df_tmp_final.mean(axis='columns') \n",
    "r.data_d[\"final_ave\"] = df_final\n",
    "r.data_d[\"final_rank\"]=r.data_d.groupby(level=0)[\"final_ave\"].rank(ascending=True,method=\"max\")\n",
    "r.data_d.drop([\"final_corner_1R_before\",\"final_corner_2R_before\",\"final_corner_3R_before\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ce1281d-a2fb-4e57-b9b5-12fdcb212999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_last = r.data_d[[\"last_1R_before\",\"last_2R_before\",\"last_3R_before\"]]\n",
    "df_last = df_tmp_last.mean(axis='columns') \n",
    "r.data_d[\"last_ave\"] = df_last\n",
    "r.data_d[\"last_rank\"]=r.data_d.groupby(level=0)[\"last_ave\"].rank(ascending=True,method=\"max\")\n",
    "r.data_d.drop([\"last_1R_before\",\"last_2R_before\",\"last_3R_before\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30eab9dc-5bf0-4c2b-86e5-4cbb843dcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d[\"final_plus_rank\"] = r.data_d[\"final_rank\"] + r.data_d[\"last_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af9abfbc-119b-4186-ab7f-008dab57d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_rank = r.data_d[[\"rank_1R_before\",\"rank_2R_before\",\"rank_3R_before\"]]\n",
    "df_rank = df_tmp_rank.mean(axis='columns') \n",
    "r.data_d[\"rank_ave\"] = df_rank\n",
    "r.data_d[\"rank_rank\"]=r.data_d.groupby(level=0)[\"rank_ave\"].rank(ascending=True,method=\"max\")\n",
    "r.data_d.drop([\"rank_1R_before\",\"rank_2R_before\",\"rank_3R_before\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71e3c9a5-c38f-4953-9aec-a1996e0218e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d.drop([\"prize\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c8ef0f9f-1738-4597-98f5-5e88b0705eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d.drop([\"frame_number\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "76a57218-ca41-4fa8-abcb-3aac6d002cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_column = [\"rank\",\"money_ave\",\"money_rank\",\"final_ave\",\"final_rank\",\"last_ave\",\"last_rank\",\"final_plus_rank\",\"rank_ave\",\"rank_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "caaa7d3d-4383-43dc-9b1c-2c935e9d3cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = r.data_d[tmp_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f24338da-e1bd-480f-9c25-89a2f4b20294",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.data_d.drop([\"money_ave\",\"final_ave\",\"final_rank\",\"last_ave\",\"last_rank\",\"rank_ave\"],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c5c5b455-3944-4f6a-8ca8-4a8837309d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>odds</th>\n",
       "      <th>favorite</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>age</th>\n",
       "      <th>weight_j</th>\n",
       "      <th>course_len</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>trainer_id</th>\n",
       "      <th>odds_1R_before</th>\n",
       "      <th>odds_2R_before</th>\n",
       "      <th>odds_3R_before</th>\n",
       "      <th>course_len_all</th>\n",
       "      <th>time_rank_p</th>\n",
       "      <th>interval</th>\n",
       "      <th>course_len_dif</th>\n",
       "      <th>peds_0</th>\n",
       "      <th>peds_4</th>\n",
       "      <th>win_rate_1_1Y_before_j</th>\n",
       "      <th>win_rate_3_1Y_before_j</th>\n",
       "      <th>prize_1Y_before_j</th>\n",
       "      <th>win_rate_1_1Y_before_t</th>\n",
       "      <th>win_rate_3_1Y_before_t</th>\n",
       "      <th>prize_1Y_before_t</th>\n",
       "      <th>race_turn_右</th>\n",
       "      <th>race_turn_左</th>\n",
       "      <th>race_turn_直</th>\n",
       "      <th>race_turn_芝</th>\n",
       "      <th>race_turn_ー</th>\n",
       "      <th>weather_晴</th>\n",
       "      <th>weather_曇</th>\n",
       "      <th>weather_雨</th>\n",
       "      <th>weather_小雨</th>\n",
       "      <th>weather_雪</th>\n",
       "      <th>weather_小雪</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>race_condition_良</th>\n",
       "      <th>race_condition_稍重</th>\n",
       "      <th>race_condition_重</th>\n",
       "      <th>race_condition_不良</th>\n",
       "      <th>sex_牡</th>\n",
       "      <th>sex_牝</th>\n",
       "      <th>sex_セ</th>\n",
       "      <th>race_park_札幌</th>\n",
       "      <th>race_park_新潟</th>\n",
       "      <th>race_park_小倉</th>\n",
       "      <th>race_park_中山</th>\n",
       "      <th>race_park_阪神</th>\n",
       "      <th>race_park_函館</th>\n",
       "      <th>race_park_京都</th>\n",
       "      <th>race_park_東京</th>\n",
       "      <th>race_park_中京</th>\n",
       "      <th>race_park_福島</th>\n",
       "      <th>money_rank</th>\n",
       "      <th>final_plus_rank</th>\n",
       "      <th>rank_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105006</td>\n",
       "      <td>01019</td>\n",
       "      <td>00379</td>\n",
       "      <td>28.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>779</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.240</td>\n",
       "      <td>96905.1</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.140</td>\n",
       "      <td>16330.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009100577</td>\n",
       "      <td>05203</td>\n",
       "      <td>01061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>763</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.333</td>\n",
       "      <td>188832.6</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.400</td>\n",
       "      <td>52106.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009102908</td>\n",
       "      <td>01093</td>\n",
       "      <td>01089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>789</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.262</td>\n",
       "      <td>137964.6</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.168</td>\n",
       "      <td>23638.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009109159</td>\n",
       "      <td>01095</td>\n",
       "      <td>01075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779</td>\n",
       "      <td>1642</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.194</td>\n",
       "      <td>95243.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.292</td>\n",
       "      <td>108027.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201101010101</th>\n",
       "      <td>5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>2009105263</td>\n",
       "      <td>01127</td>\n",
       "      <td>01026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>969</td>\n",
       "      <td>1891</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.284</td>\n",
       "      <td>114614.3</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.167</td>\n",
       "      <td>23687.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rank  odds  favorite  horse_number  age  weight_j  course_len  \\\n",
       "201101010101     1   4.7       3.0             2    2      54.0          18   \n",
       "201101010101     2   3.4       2.0             3    2      54.0          18   \n",
       "201101010101     3   2.1       1.0             5    2      54.0          18   \n",
       "201101010101     4   7.0       4.0             4    2      54.0          18   \n",
       "201101010101     5  17.5       5.0             1    2      54.0          18   \n",
       "\n",
       "              n_horses       date    horse_id jockey_id trainer_id  \\\n",
       "201101010101         7 2011-08-13  2009105006     01019      00379   \n",
       "201101010101         7 2011-08-13  2009100577     05203      01061   \n",
       "201101010101         7 2011-08-13  2009102908     01093      01089   \n",
       "201101010101         7 2011-08-13  2009109159     01095      01075   \n",
       "201101010101         7 2011-08-13  2009105263     01127      01026   \n",
       "\n",
       "              odds_1R_before  odds_2R_before  odds_3R_before  course_len_all  \\\n",
       "201101010101            28.8             NaN             NaN            14.0   \n",
       "201101010101             NaN             NaN             NaN             NaN   \n",
       "201101010101             NaN             NaN             NaN             NaN   \n",
       "201101010101             NaN             NaN             NaN             NaN   \n",
       "201101010101             NaN             NaN             NaN             NaN   \n",
       "\n",
       "              time_rank_p  interval  course_len_dif peds_0 peds_4  \\\n",
       "201101010101          1.0      34.0             4.0    779   1457   \n",
       "201101010101          NaN       NaN             NaN    763   1637   \n",
       "201101010101          NaN       NaN             NaN    789   1457   \n",
       "201101010101          NaN       NaN             NaN    779   1642   \n",
       "201101010101          NaN       NaN             NaN    969   1891   \n",
       "\n",
       "              win_rate_1_1Y_before_j  win_rate_3_1Y_before_j  \\\n",
       "201101010101                   0.084                   0.240   \n",
       "201101010101                   0.119                   0.333   \n",
       "201101010101                   0.086                   0.262   \n",
       "201101010101                   0.069                   0.194   \n",
       "201101010101                   0.110                   0.284   \n",
       "\n",
       "              prize_1Y_before_j  win_rate_1_1Y_before_t  \\\n",
       "201101010101            96905.1                   0.062   \n",
       "201101010101           188832.6                   0.138   \n",
       "201101010101           137964.6                   0.051   \n",
       "201101010101            95243.0                   0.087   \n",
       "201101010101           114614.3                   0.062   \n",
       "\n",
       "              win_rate_3_1Y_before_t  prize_1Y_before_t  race_turn_右  \\\n",
       "201101010101                   0.140            16330.6            1   \n",
       "201101010101                   0.400            52106.2            1   \n",
       "201101010101                   0.168            23638.6            1   \n",
       "201101010101                   0.292           108027.3            1   \n",
       "201101010101                   0.167            23687.4            1   \n",
       "\n",
       "              race_turn_左  race_turn_直  race_turn_芝  race_turn_ー  weather_晴  \\\n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "201101010101            0            0            0            0          1   \n",
       "\n",
       "              weather_曇  weather_雨  weather_小雨  weather_雪  weather_小雪  \\\n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "201101010101          0          0           0          0           0   \n",
       "\n",
       "              race_type_芝  race_type_ダート  race_type_障害  race_condition_良  \\\n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "201101010101            1              0             0                 1   \n",
       "\n",
       "              race_condition_稍重  race_condition_重  race_condition_不良  sex_牡  \\\n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      1   \n",
       "201101010101                  0                 0                  0      0   \n",
       "\n",
       "              sex_牝  sex_セ  race_park_札幌  race_park_新潟  race_park_小倉  \\\n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      0      0             1             0             0   \n",
       "201101010101      1      0             1             0             0   \n",
       "\n",
       "              race_park_中山  race_park_阪神  race_park_函館  race_park_京都  \\\n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "201101010101             0             0             0             0   \n",
       "\n",
       "              race_park_東京  race_park_中京  race_park_福島  money_rank  \\\n",
       "201101010101             0             0             0         1.0   \n",
       "201101010101             0             0             0         NaN   \n",
       "201101010101             0             0             0         NaN   \n",
       "201101010101             0             0             0         NaN   \n",
       "201101010101             0             0             0         NaN   \n",
       "\n",
       "              final_plus_rank  rank_rank  \n",
       "201101010101              2.0        1.0  \n",
       "201101010101              NaN        NaN  \n",
       "201101010101              NaN        NaN  \n",
       "201101010101              NaN        NaN  \n",
       "201101010101              NaN        NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "429b443d-e435-4ec7-8163-3a09cf4f50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61a1783c-2c63-4547-95fe-75b28e2c3b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "mask = np.triu(np.ones_like(tmp_df.corr(method=\"spearman\"), dtype=bool))\n",
    "f, ax = plt.subplots(figsize=(40, 20))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(tmp_df.corr(method=\"spearman\"),mask = mask, annot = True,cmap = cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "57f0bb11-6497-4a8e-ae8a-691291eca3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(x):\n",
    "    if x >= 1 and x <= 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "r.data_d['rank'] = r.data_d['rank'].map(lambda x: rank(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9160a384-11f6-4649-9a39-5d43f252118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]\n",
    "    test = df.loc[test_id_list]\n",
    "    return train, test\n",
    "\n",
    "train, test = split_data(r.data_d)\n",
    "\n",
    "train, valid = split_data(train)\n",
    "\n",
    "X_train = train.drop(['rank', 'date',\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_train = train['rank']\n",
    "X_valid = valid.drop(['rank', 'date',\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_valid = valid['rank']\n",
    "\n",
    "#データセットを作成\n",
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_valid = lgb_o.Dataset(X_valid.values, y_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a69a307d-302d-459b-8648-deca645608d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数と目的変数に分ける。dateはこの後不要なので省く。\n",
    "X_train = train.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_test = test['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ee3b86b-e23a-4460-abbd-c865fab4ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary', #今回は0or1の二値予測なのでbinaryを指定\n",
    "    'random_state': 100,\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "233c5955-2756-4d2e-96a1-07f048546a72",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-13 11:04:38,848]\u001b[0m A new study created in memory with name: no-name-ceb3f4aa-4f2f-49ef-a71f-712da7b1e483\u001b[0m\n",
      "feature_fraction, val_score: -inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.784865\tvalid_1's auc: 0.81447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.814532:  14%|#4        | 1/7 [00:04<00:24,  4.11s/it]\u001b[32m[I 2021-11-13 11:04:42,981]\u001b[0m Trial 0 finished with value: 0.8145320011992654 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.8145320011992654.\u001b[0m\n",
      "feature_fraction, val_score: 0.814532:  14%|#4        | 1/7 [00:04<00:24,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.787683\tvalid_1's auc: 0.814532\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.814532:  29%|##8       | 2/7 [00:07<00:18,  3.66s/it]\u001b[32m[I 2021-11-13 11:04:46,313]\u001b[0m Trial 1 finished with value: 0.8138583130214958 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8145320011992654.\u001b[0m\n",
      "feature_fraction, val_score: 0.814532:  29%|##8       | 2/7 [00:07<00:18,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.781156\tvalid_1's auc: 0.813858\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.814532:  43%|####2     | 3/7 [00:10<00:14,  3.59s/it]\u001b[32m[I 2021-11-13 11:04:49,815]\u001b[0m Trial 2 finished with value: 0.8145308047237138 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8145320011992654.\u001b[0m\n",
      "feature_fraction, val_score: 0.814532:  43%|####2     | 3/7 [00:10<00:14,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.783332\tvalid_1's auc: 0.814364\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.782309\tvalid_1's auc: 0.814531\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.814532:  57%|#####7    | 4/7 [00:13<00:09,  3.31s/it]\u001b[32m[I 2021-11-13 11:04:52,704]\u001b[0m Trial 3 finished with value: 0.8143947724281599 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8145320011992654.\u001b[0m\n",
      "feature_fraction, val_score: 0.814532:  57%|#####7    | 4/7 [00:13<00:09,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.780043\tvalid_1's auc: 0.814395\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.78269\tvalid_1's auc: 0.815163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815320:  71%|#######1  | 5/7 [00:17<00:06,  3.42s/it]\u001b[32m[I 2021-11-13 11:04:56,315]\u001b[0m Trial 4 finished with value: 0.8153202932705451 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.8153202932705451.\u001b[0m\n",
      "feature_fraction, val_score: 0.815320:  71%|#######1  | 5/7 [00:17<00:06,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.783687\tvalid_1's auc: 0.81532\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.783072\tvalid_1's auc: 0.814505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815320:  86%|########5 | 6/7 [00:20<00:03,  3.45s/it]\u001b[32m[I 2021-11-13 11:04:59,813]\u001b[0m Trial 5 finished with value: 0.8145266411505255 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.8153202932705451.\u001b[0m\n",
      "feature_fraction, val_score: 0.815320:  86%|########5 | 6/7 [00:20<00:03,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.78431\tvalid_1's auc: 0.814527\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.815320: 100%|##########| 7/7 [00:24<00:00,  3.35s/it]\u001b[32m[I 2021-11-13 11:05:02,967]\u001b[0m Trial 6 finished with value: 0.8144647141906306 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.8153202932705451.\u001b[0m\n",
      "feature_fraction, val_score: 0.815320: 100%|##########| 7/7 [00:24<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.784487\tvalid_1's auc: 0.814433\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.783152\tvalid_1's auc: 0.814465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815320:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815320:   5%|5         | 1/20 [00:03<01:02,  3.27s/it]\u001b[32m[I 2021-11-13 11:05:06,245]\u001b[0m Trial 7 finished with value: 0.8129110254888512 and parameters: {'num_leaves': 202}. Best is trial 7 with value: 0.8129110254888512.\u001b[0m\n",
      "num_leaves, val_score: 0.815320:   5%|5         | 1/20 [00:03<01:02,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.819887\tvalid_1's auc: 0.812911\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815320:  10%|#         | 2/20 [00:06<00:54,  3.01s/it]\u001b[32m[I 2021-11-13 11:05:09,064]\u001b[0m Trial 8 finished with value: 0.8142398967377243 and parameters: {'num_leaves': 81}. Best is trial 8 with value: 0.8142398967377243.\u001b[0m\n",
      "num_leaves, val_score: 0.815320:  10%|#         | 2/20 [00:06<00:54,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.793594\tvalid_1's auc: 0.81424\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  15%|#5        | 3/20 [00:09<00:55,  3.24s/it]\u001b[32m[I 2021-11-13 11:05:12,575]\u001b[0m Trial 9 finished with value: 0.8155992230233999 and parameters: {'num_leaves': 72}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  15%|#5        | 3/20 [00:09<00:55,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.800498\tvalid_1's auc: 0.815599\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  20%|##        | 4/20 [00:12<00:51,  3.20s/it]\u001b[32m[I 2021-11-13 11:05:15,727]\u001b[0m Trial 10 finished with value: 0.8136580484194619 and parameters: {'num_leaves': 155}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  20%|##        | 4/20 [00:12<00:51,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.808776\tvalid_1's auc: 0.813658\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  25%|##5       | 5/20 [00:16<00:48,  3.25s/it]\u001b[32m[I 2021-11-13 11:05:19,064]\u001b[0m Trial 11 finished with value: 0.8129588895650236 and parameters: {'num_leaves': 193}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  25%|##5       | 5/20 [00:16<00:48,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.817672\tvalid_1's auc: 0.812959\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  30%|###       | 6/20 [00:19<00:44,  3.19s/it]\u001b[32m[I 2021-11-13 11:05:22,131]\u001b[0m Trial 12 finished with value: 0.8133058769093312 and parameters: {'num_leaves': 167}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  30%|###       | 6/20 [00:19<00:44,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.81171\tvalid_1's auc: 0.813306\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  35%|###5      | 7/20 [00:22<00:42,  3.26s/it]\u001b[32m[I 2021-11-13 11:05:25,533]\u001b[0m Trial 13 finished with value: 0.8150055774090267 and parameters: {'num_leaves': 39}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  35%|###5      | 7/20 [00:22<00:42,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.787032\tvalid_1's auc: 0.814947\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.785068\tvalid_1's auc: 0.815006\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  40%|####      | 8/20 [00:26<00:40,  3.37s/it]\u001b[32m[I 2021-11-13 11:05:29,137]\u001b[0m Trial 14 finished with value: 0.8140074401708483 and parameters: {'num_leaves': 104}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  40%|####      | 8/20 [00:26<00:40,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.803184\tvalid_1's auc: 0.814007\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  45%|####5     | 9/20 [00:29<00:37,  3.41s/it]\u001b[32m[I 2021-11-13 11:05:32,650]\u001b[0m Trial 15 finished with value: 0.81415511173744 and parameters: {'num_leaves': 94}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  45%|####5     | 9/20 [00:29<00:37,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.803378\tvalid_1's auc: 0.814155\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  50%|#####     | 10/20 [00:32<00:33,  3.36s/it]\u001b[32m[I 2021-11-13 11:05:35,889]\u001b[0m Trial 16 finished with value: 0.8128298420450781 and parameters: {'num_leaves': 194}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  50%|#####     | 10/20 [00:32<00:33,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.82258\tvalid_1's auc: 0.81283\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.766376\tvalid_1's auc: 0.812292\n",
      "[200]\tvalid_0's auc: 0.772759\tvalid_1's auc: 0.814027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  55%|#####5    | 11/20 [00:38<00:35,  3.94s/it]\u001b[32m[I 2021-11-13 11:05:41,148]\u001b[0m Trial 17 finished with value: 0.8142357907813537 and parameters: {'num_leaves': 9}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  55%|#####5    | 11/20 [00:38<00:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's auc: 0.775106\tvalid_1's auc: 0.814236\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.778665\tvalid_1's auc: 0.815093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  60%|######    | 12/20 [00:41<00:30,  3.80s/it]\u001b[32m[I 2021-11-13 11:05:44,639]\u001b[0m Trial 18 finished with value: 0.8153832020749224 and parameters: {'num_leaves': 25}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  60%|######    | 12/20 [00:41<00:30,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.780866\tvalid_1's auc: 0.815383\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  65%|######5   | 13/20 [00:44<00:25,  3.64s/it]\u001b[32m[I 2021-11-13 11:05:47,917]\u001b[0m Trial 19 finished with value: 0.8153780320605984 and parameters: {'num_leaves': 41}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  65%|######5   | 13/20 [00:44<00:25,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.788388\tvalid_1's auc: 0.815311\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.786438\tvalid_1's auc: 0.815378\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.761222\tvalid_1's auc: 0.809722\n",
      "[200]\tvalid_0's auc: 0.766074\tvalid_1's auc: 0.81207\n",
      "[300]\tvalid_0's auc: 0.768945\tvalid_1's auc: 0.813137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  70%|#######   | 14/20 [00:52<00:28,  4.74s/it]\u001b[32m[I 2021-11-13 11:05:55,196]\u001b[0m Trial 20 finished with value: 0.8137270942572657 and parameters: {'num_leaves': 5}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  70%|#######   | 14/20 [00:52<00:28,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[388]\tvalid_0's auc: 0.77106\tvalid_1's auc: 0.813727\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  75%|#######5  | 15/20 [00:55<00:21,  4.28s/it]\u001b[32m[I 2021-11-13 11:05:58,406]\u001b[0m Trial 21 finished with value: 0.8153523278841953 and parameters: {'num_leaves': 54}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  75%|#######5  | 15/20 [00:55<00:21,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.792399\tvalid_1's auc: 0.815352\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  80%|########  | 16/20 [00:58<00:15,  3.80s/it]\u001b[32m[I 2021-11-13 11:06:01,093]\u001b[0m Trial 22 finished with value: 0.8135834855186665 and parameters: {'num_leaves': 123}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  80%|########  | 16/20 [00:58<00:15,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.800311\tvalid_1's auc: 0.813583\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  85%|########5 | 17/20 [01:01<00:10,  3.65s/it]\u001b[32m[I 2021-11-13 11:06:04,383]\u001b[0m Trial 23 finished with value: 0.814962170381178 and parameters: {'num_leaves': 69}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  85%|########5 | 17/20 [01:01<00:10,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.797269\tvalid_1's auc: 0.814962\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  90%|######### | 18/20 [01:04<00:07,  3.53s/it]\u001b[32m[I 2021-11-13 11:06:07,643]\u001b[0m Trial 24 finished with value: 0.812143901701585 and parameters: {'num_leaves': 248}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  90%|######### | 18/20 [01:04<00:07,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.828591\tvalid_1's auc: 0.812144\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.773235\tvalid_1's auc: 0.814522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599:  95%|#########5| 19/20 [01:08<00:03,  3.64s/it]\u001b[32m[I 2021-11-13 11:06:11,533]\u001b[0m Trial 25 finished with value: 0.8151496036168482 and parameters: {'num_leaves': 17}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599:  95%|#########5| 19/20 [01:08<00:03,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.778577\tvalid_1's auc: 0.81515\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.780718\tvalid_1's auc: 0.814779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.815599: 100%|##########| 20/20 [01:12<00:00,  3.83s/it]\u001b[32m[I 2021-11-13 11:06:15,801]\u001b[0m Trial 26 finished with value: 0.8153351843539032 and parameters: {'num_leaves': 29}. Best is trial 9 with value: 0.8155992230233999.\u001b[0m\n",
      "num_leaves, val_score: 0.815599: 100%|##########| 20/20 [01:12<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.789589\tvalid_1's auc: 0.815335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  10%|#         | 1/10 [00:03<00:28,  3.21s/it]\u001b[32m[I 2021-11-13 11:06:19,012]\u001b[0m Trial 27 finished with value: 0.8146914431067317 and parameters: {'bagging_fraction': 0.9797531610980145, 'bagging_freq': 6}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  10%|#         | 1/10 [00:03<00:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.792462\tvalid_1's auc: 0.814691\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  20%|##        | 2/10 [00:06<00:24,  3.04s/it]\u001b[32m[I 2021-11-13 11:06:21,931]\u001b[0m Trial 28 finished with value: 0.8135158305710561 and parameters: {'bagging_fraction': 0.6732056135103948, 'bagging_freq': 4}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  20%|##        | 2/10 [00:06<00:24,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.789598\tvalid_1's auc: 0.813516\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  30%|###       | 3/10 [00:10<00:24,  3.44s/it]\u001b[32m[I 2021-11-13 11:06:25,849]\u001b[0m Trial 29 finished with value: 0.8145807120067983 and parameters: {'bagging_fraction': 0.8028370197894592, 'bagging_freq': 2}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  30%|###       | 3/10 [00:10<00:24,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.799356\tvalid_1's auc: 0.814581\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  40%|####      | 4/10 [00:12<00:19,  3.20s/it]\u001b[32m[I 2021-11-13 11:06:28,679]\u001b[0m Trial 30 finished with value: 0.8123304090248881 and parameters: {'bagging_fraction': 0.5269800069813398, 'bagging_freq': 2}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  40%|####      | 4/10 [00:12<00:19,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.789033\tvalid_1's auc: 0.81233\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  50%|#####     | 5/10 [00:16<00:17,  3.44s/it]\u001b[32m[I 2021-11-13 11:06:32,542]\u001b[0m Trial 31 finished with value: 0.8145536866868756 and parameters: {'bagging_fraction': 0.7226825861823786, 'bagging_freq': 3}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  50%|#####     | 5/10 [00:16<00:17,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.803649\tvalid_1's auc: 0.814322\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.801738\tvalid_1's auc: 0.814554\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  60%|######    | 6/10 [00:19<00:12,  3.08s/it]\u001b[32m[I 2021-11-13 11:06:34,936]\u001b[0m Trial 32 finished with value: 0.8111736931206861 and parameters: {'bagging_fraction': 0.41453597473142134, 'bagging_freq': 3}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  60%|######    | 6/10 [00:19<00:12,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.783234\tvalid_1's auc: 0.811174\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  70%|#######   | 7/10 [00:23<00:10,  3.35s/it]\u001b[32m[I 2021-11-13 11:06:38,829]\u001b[0m Trial 33 finished with value: 0.8140992921602117 and parameters: {'bagging_fraction': 0.9278476411559463, 'bagging_freq': 5}. Best is trial 27 with value: 0.8146914431067317.\u001b[0m\n",
      "bagging, val_score: 0.815599:  70%|#######   | 7/10 [00:23<00:10,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.795981\tvalid_1's auc: 0.814099\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  80%|########  | 8/10 [00:26<00:06,  3.31s/it]\u001b[32m[I 2021-11-13 11:06:42,050]\u001b[0m Trial 34 finished with value: 0.8149271952881869 and parameters: {'bagging_fraction': 0.9965835632104488, 'bagging_freq': 1}. Best is trial 34 with value: 0.8149271952881869.\u001b[0m\n",
      "bagging, val_score: 0.815599:  80%|########  | 8/10 [00:26<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.792622\tvalid_1's auc: 0.814927\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599:  90%|######### | 9/10 [00:29<00:03,  3.25s/it]\u001b[32m[I 2021-11-13 11:06:45,180]\u001b[0m Trial 35 finished with value: 0.8139462238183706 and parameters: {'bagging_fraction': 0.7652769443314785, 'bagging_freq': 5}. Best is trial 34 with value: 0.8149271952881869.\u001b[0m\n",
      "bagging, val_score: 0.815599:  90%|######### | 9/10 [00:29<00:03,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.791411\tvalid_1's auc: 0.813946\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.815599: 100%|##########| 10/10 [00:32<00:00,  3.06s/it]\u001b[32m[I 2021-11-13 11:06:47,812]\u001b[0m Trial 36 finished with value: 0.8127371574758532 and parameters: {'bagging_fraction': 0.5038227122646897, 'bagging_freq': 4}. Best is trial 34 with value: 0.8149271952881869.\u001b[0m\n",
      "bagging, val_score: 0.815599: 100%|##########| 10/10 [00:32<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.78581\tvalid_1's auc: 0.812737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.815599:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.815599:  33%|###3      | 1/3 [00:03<00:07,  3.52s/it]\u001b[32m[I 2021-11-13 11:06:51,344]\u001b[0m Trial 37 finished with value: 0.8155992230233999 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.8155992230233999.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.815599:  33%|###3      | 1/3 [00:03<00:07,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.800498\tvalid_1's auc: 0.815599\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.815599:  67%|######6   | 2/3 [00:06<00:03,  3.36s/it]\u001b[32m[I 2021-11-13 11:06:54,590]\u001b[0m Trial 38 finished with value: 0.8148355754507962 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.8155992230233999.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.815599:  67%|######6   | 2/3 [00:06<00:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.795565\tvalid_1's auc: 0.814836\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.815599: 100%|##########| 3/3 [00:09<00:00,  3.24s/it]\u001b[32m[I 2021-11-13 11:06:57,684]\u001b[0m Trial 39 finished with value: 0.8146538125860239 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.8155992230233999.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.815599: 100%|##########| 3/3 [00:09<00:00,  3.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.79564\tvalid_1's auc: 0.814654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.79931\tvalid_1's auc: 0.815364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:   5%|5         | 1/20 [00:04<01:24,  4.43s/it]\u001b[32m[I 2021-11-13 11:07:02,122]\u001b[0m Trial 40 finished with value: 0.8154954938830381 and parameters: {'lambda_l1': 2.8336661933621694, 'lambda_l2': 1.8521203597706264}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:   5%|5         | 1/20 [00:04<01:24,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.801589\tvalid_1's auc: 0.815495\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  10%|#         | 2/20 [00:07<01:08,  3.82s/it]\u001b[32m[I 2021-11-13 11:07:05,519]\u001b[0m Trial 41 finished with value: 0.8147520691395342 and parameters: {'lambda_l1': 0.003499956413759099, 'lambda_l2': 0.17668535986337167}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  10%|#         | 2/20 [00:07<01:08,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.797848\tvalid_1's auc: 0.814752\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.800461\tvalid_1's auc: 0.815405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  15%|#5        | 3/20 [00:11<01:07,  3.95s/it]\u001b[32m[I 2021-11-13 11:07:09,629]\u001b[0m Trial 42 finished with value: 0.8154490944870187 and parameters: {'lambda_l1': 0.2979949788792183, 'lambda_l2': 2.9726901691304306}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  15%|#5        | 3/20 [00:11<01:07,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.799969\tvalid_1's auc: 0.815449\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  20%|##        | 4/20 [00:15<01:02,  3.90s/it]\u001b[32m[I 2021-11-13 11:07:13,443]\u001b[0m Trial 43 finished with value: 0.8153872510883564 and parameters: {'lambda_l1': 0.16567870164677803, 'lambda_l2': 0.9279086062062771}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  20%|##        | 4/20 [00:15<01:02,  3.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.802078\tvalid_1's auc: 0.815304\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.800392\tvalid_1's auc: 0.815387\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  25%|##5       | 5/20 [00:19<00:57,  3.82s/it]\u001b[32m[I 2021-11-13 11:07:17,122]\u001b[0m Trial 44 finished with value: 0.8149402092762766 and parameters: {'lambda_l1': 0.0005868933760375925, 'lambda_l2': 4.7097896292540645e-08}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  25%|##5       | 5/20 [00:19<00:57,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.804688\tvalid_1's auc: 0.814886\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.801803\tvalid_1's auc: 0.81494\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  30%|###       | 6/20 [00:23<00:52,  3.76s/it]\u001b[32m[I 2021-11-13 11:07:20,759]\u001b[0m Trial 45 finished with value: 0.8150364428393021 and parameters: {'lambda_l1': 0.0009537129474945647, 'lambda_l2': 0.0005283563736972757}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  30%|###       | 6/20 [00:23<00:52,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.798361\tvalid_1's auc: 0.815036\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815599:  35%|###5      | 7/20 [00:26<00:48,  3.70s/it]\u001b[32m[I 2021-11-13 11:07:24,344]\u001b[0m Trial 46 finished with value: 0.8150419039701782 and parameters: {'lambda_l1': 0.0005735565885306231, 'lambda_l2': 0.00023870885399466228}. Best is trial 40 with value: 0.8154954938830381.\u001b[0m\n",
      "regularization_factors, val_score: 0.815599:  35%|###5      | 7/20 [00:26<00:48,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.798359\tvalid_1's auc: 0.815042\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.799368\tvalid_1's auc: 0.815743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815815:  40%|####      | 8/20 [00:31<00:47,  3.94s/it]\u001b[32m[I 2021-11-13 11:07:28,796]\u001b[0m Trial 47 finished with value: 0.8158146027741938 and parameters: {'lambda_l1': 3.5898120801712246, 'lambda_l2': 0.053140698461189184}. Best is trial 47 with value: 0.8158146027741938.\u001b[0m\n",
      "regularization_factors, val_score: 0.815815:  40%|####      | 8/20 [00:31<00:47,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.798871\tvalid_1's auc: 0.815815\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815815:  45%|####5     | 9/20 [00:34<00:43,  3.91s/it]\u001b[32m[I 2021-11-13 11:07:32,655]\u001b[0m Trial 48 finished with value: 0.8152878860007529 and parameters: {'lambda_l1': 6.704943968627619e-05, 'lambda_l2': 1.3089744604192146e-06}. Best is trial 47 with value: 0.8158146027741938.\u001b[0m\n",
      "regularization_factors, val_score: 0.815815:  45%|####5     | 9/20 [00:34<00:43,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.800357\tvalid_1's auc: 0.815288\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815815:  50%|#####     | 10/20 [00:38<00:38,  3.81s/it]\u001b[32m[I 2021-11-13 11:07:36,219]\u001b[0m Trial 49 finished with value: 0.8148925618528161 and parameters: {'lambda_l1': 0.0007690664497529886, 'lambda_l2': 0.0033065104067531224}. Best is trial 47 with value: 0.8158146027741938.\u001b[0m\n",
      "regularization_factors, val_score: 0.815815:  50%|#####     | 10/20 [00:38<00:38,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.796517\tvalid_1's auc: 0.814893\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.815815:  55%|#####5    | 11/20 [00:42<00:34,  3.85s/it]\u001b[32m[I 2021-11-13 11:07:40,173]\u001b[0m Trial 50 finished with value: 0.8153875037936968 and parameters: {'lambda_l1': 7.594041388236353e-08, 'lambda_l2': 0.026054768313996786}. Best is trial 47 with value: 0.8158146027741938.\u001b[0m\n",
      "regularization_factors, val_score: 0.815815:  55%|#####5    | 11/20 [00:42<00:34,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.804016\tvalid_1's auc: 0.815252\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.802896\tvalid_1's auc: 0.815388\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795337\tvalid_1's auc: 0.815877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  60%|######    | 12/20 [00:47<00:34,  4.29s/it]\u001b[32m[I 2021-11-13 11:07:45,453]\u001b[0m Trial 51 finished with value: 0.816103033910907 and parameters: {'lambda_l1': 6.895394500666614, 'lambda_l2': 6.761834592104166}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  60%|######    | 12/20 [00:47<00:34,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.801067\tvalid_1's auc: 0.816103\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  65%|######5   | 13/20 [00:52<00:29,  4.28s/it]\u001b[32m[I 2021-11-13 11:07:49,715]\u001b[0m Trial 52 finished with value: 0.8155276831523567 and parameters: {'lambda_l1': 9.275084488138864, 'lambda_l2': 0.041059813955899686}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  65%|######5   | 13/20 [00:52<00:29,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.794869\tvalid_1's auc: 0.815452\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.793374\tvalid_1's auc: 0.815528\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.799452\tvalid_1's auc: 0.81532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  70%|#######   | 14/20 [00:56<00:25,  4.33s/it]\u001b[32m[I 2021-11-13 11:07:54,151]\u001b[0m Trial 53 finished with value: 0.8154077404373553 and parameters: {'lambda_l1': 0.12825073380056543, 'lambda_l2': 5.053775739441189}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  70%|#######   | 14/20 [00:56<00:25,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.802297\tvalid_1's auc: 0.815408\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  75%|#######5  | 15/20 [01:00<00:20,  4.15s/it]\u001b[32m[I 2021-11-13 11:07:57,885]\u001b[0m Trial 54 finished with value: 0.8155981731169458 and parameters: {'lambda_l1': 2.3046462099704894e-06, 'lambda_l2': 8.967232993365511e-05}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  75%|#######5  | 15/20 [01:00<00:20,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.800498\tvalid_1's auc: 0.815598\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795373\tvalid_1's auc: 0.815708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  80%|########  | 16/20 [01:04<00:16,  4.17s/it]\u001b[32m[I 2021-11-13 11:08:02,111]\u001b[0m Trial 55 finished with value: 0.8157999195830957 and parameters: {'lambda_l1': 4.977798804388649, 'lambda_l2': 8.37493455502336}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  80%|########  | 16/20 [01:04<00:16,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.794747\tvalid_1's auc: 0.8158\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  85%|########5 | 17/20 [01:08<00:12,  4.01s/it]\u001b[32m[I 2021-11-13 11:08:05,754]\u001b[0m Trial 56 finished with value: 0.814942856954363 and parameters: {'lambda_l1': 0.019929268345170996, 'lambda_l2': 0.15351972733733973}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  85%|########5 | 17/20 [01:08<00:12,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.799947\tvalid_1's auc: 0.814943\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  90%|######### | 18/20 [01:11<00:07,  3.93s/it]\u001b[32m[I 2021-11-13 11:08:09,499]\u001b[0m Trial 57 finished with value: 0.8152395310023393 and parameters: {'lambda_l1': 1.8739543533303527, 'lambda_l2': 0.00695572239733223}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  90%|######### | 18/20 [01:11<00:07,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.798188\tvalid_1's auc: 0.81524\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103:  95%|#########5| 19/20 [01:15<00:03,  3.86s/it]\u001b[32m[I 2021-11-13 11:08:13,180]\u001b[0m Trial 58 finished with value: 0.8155977836137811 and parameters: {'lambda_l1': 2.4495995709486317e-05, 'lambda_l2': 1.220469521121828e-05}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103:  95%|#########5| 19/20 [01:15<00:03,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.800498\tvalid_1's auc: 0.815598\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.816103: 100%|##########| 20/20 [01:19<00:00,  3.87s/it]\u001b[32m[I 2021-11-13 11:08:17,068]\u001b[0m Trial 59 finished with value: 0.8153630702197451 and parameters: {'lambda_l1': 0.01508659990898758, 'lambda_l2': 0.4039634838367223}. Best is trial 51 with value: 0.816103033910907.\u001b[0m\n",
      "regularization_factors, val_score: 0.816103: 100%|##########| 20/20 [01:19<00:00,  3.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.803105\tvalid_1's auc: 0.814985\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.801216\tvalid_1's auc: 0.815363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816103:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795165\tvalid_1's auc: 0.815905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816103:  20%|##        | 1/5 [00:04<00:19,  4.79s/it]\u001b[32m[I 2021-11-13 11:08:21,865]\u001b[0m Trial 60 finished with value: 0.8160913353383492 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.8160913353383492.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.816103:  20%|##        | 1/5 [00:04<00:19,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.798141\tvalid_1's auc: 0.816091\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.794987\tvalid_1's auc: 0.815574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816103:  40%|####      | 2/5 [00:10<00:15,  5.30s/it]\u001b[32m[I 2021-11-13 11:08:27,526]\u001b[0m Trial 61 finished with value: 0.816054368253395 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.8160913353383492.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.816103:  40%|####      | 2/5 [00:10<00:15,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.803216\tvalid_1's auc: 0.816054\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795349\tvalid_1's auc: 0.815854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816131:  60%|######    | 3/5 [00:15<00:10,  5.13s/it]\u001b[32m[I 2021-11-13 11:08:32,454]\u001b[0m Trial 62 finished with value: 0.8161308004998282 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.8161308004998282.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.816131:  60%|######    | 3/5 [00:15<00:10,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.798804\tvalid_1's auc: 0.816131\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795295\tvalid_1's auc: 0.815673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816131:  80%|########  | 4/5 [00:20<00:04,  4.98s/it]\u001b[32m[I 2021-11-13 11:08:37,191]\u001b[0m Trial 63 finished with value: 0.8160253307250818 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.8161308004998282.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.816131:  80%|########  | 4/5 [00:20<00:04,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.798371\tvalid_1's auc: 0.816025\n",
      "[LightGBM] [Info] Number of positive: 186344, number of negative: 43984\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3347\n",
      "[LightGBM] [Info] Number of data points in the train set: 230328, number of used features: 54\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.809038 -> initscore=1.443768\n",
      "[LightGBM] [Info] Start training from score 1.443768\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's auc: 0.795113\tvalid_1's auc: 0.815691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.816131: 100%|##########| 5/5 [00:24<00:00,  4.93s/it]\u001b[32m[I 2021-11-13 11:08:42,026]\u001b[0m Trial 64 finished with value: 0.8158110709643566 and parameters: {'min_child_samples': 25}. Best is trial 62 with value: 0.8161308004998282.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.816131: 100%|##########| 5/5 [00:24<00:00,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.79707\tvalid_1's auc: 0.815811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_clf_o = lgb_o.train(params, lgb_train,\n",
    "                        valid_sets=(lgb_train, lgb_valid),\n",
    "                        verbose_eval=100,\n",
    "                        early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee986e90-fa2a-4c35-a77c-a138ab59393b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'random_state': 100,\n",
       " 'metric': 'auc',\n",
       " 'boosting': 'gbdt',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 6.895394500666614,\n",
       " 'lambda_l2': 6.761834592104166,\n",
       " 'num_leaves': 72,\n",
       " 'feature_fraction': 0.4,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 5,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf_o.params#確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e8710e54-e398-4755-8362-fc036daeb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(r.data_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "be7e4b5d-2187-4004-8529-0ac7eac36b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数と目的変数に分ける。dateはこの後不要なので省く。\n",
    "X_train = train.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_train = train['rank']\n",
    "X_test = test.drop([\"rank\", \"date\",\"horse_id\",\"jockey_id\",\"trainer_id\",\"favorite\",\"odds\"], axis=1)\n",
    "y_test = test['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5eb4270a-6a4e-4d8b-85ee-41ef9a54401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf_o.params2={\n",
    "'objective': 'binary',\n",
    " 'random_state': 100,\n",
    " 'metric': 'auc',\n",
    " 'boosting': 'gbdt',\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 6.895394500666614,\n",
    " 'lambda_l2': 6.761834592104166,\n",
    " 'num_leaves': 72,\n",
    " 'feature_fraction': 0.4,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 0,\n",
    " 'min_child_samples': 5,\n",
    " 'num_iterations': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bfe41845-cb82-4828-b64d-80efcd4c28c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.761834592104166, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.761834592104166\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895394500666614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895394500666614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=1.0, bagging_freq=0, boosting='gbdt',\n",
       "               feature_fraction=0.4, feature_pre_filter=False,\n",
       "               lambda_l1=6.895394500666614, lambda_l2=6.761834592104166,\n",
       "               metric='auc', min_child_samples=5, num_iterations=1000,\n",
       "               num_leaves=72, objective='binary', random_state=100)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(**lgb_clf_o.params2)\n",
    "lgb_clf.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a6237c7-40c1-42f9-9e73-27b4eba01cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率(test) 0.8158603542940018\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('正解率(test)',accuracy_score(y_test, lgb_clf.predict(X_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6d69335-3532-4171-8770-a51726f172e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: axis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6086683541939306"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lgb_clf.predict(X_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "79db6b3c-da46-4b1f-932e-334bd21a58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "723d0889-99d2-4cbc-a5f4-655ce87eba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.761834592104166, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.761834592104166\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895394500666614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895394500666614\n",
      "0.592349229511664\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.761834592104166, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.761834592104166\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895394500666614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895394500666614\n",
      "0.5905589172968416\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.761834592104166, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.761834592104166\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895394500666614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895394500666614\n",
      "0.5909916225855911\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.761834592104166, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.761834592104166\n",
      "[LightGBM] [Warning] lambda_l1 is set=6.895394500666614, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.895394500666614\n",
      "0.5906676857607018\n",
      "0.5911418637886996\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits = 4,shuffle = True,random_state=71)\n",
    "for tr_idx,va_idx in kf.split(X_train,y_train.values):\n",
    "    tr_x,va_x = X_train.iloc[tr_idx].values,X_train.iloc[va_idx].values\n",
    "    tr_y,va_y = y_train.iloc[tr_idx],y_train.iloc[va_idx]\n",
    "    \n",
    "    lgb_clf = lgb.LGBMClassifier(**lgb_clf_o.params2)\n",
    "    lgb_clf.fit(tr_x,tr_y)\n",
    "    va_pred = lgb_clf.predict(va_x)\n",
    "    score = roc_auc_score(va_y,va_pred)\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "47f7e258-a28c-4453-89ff-a82e2d8001c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X, n_display=20):\n",
    "    importances = pd.DataFrame({\"features\": X.columns, \n",
    "                                \"importance\": lgb_clf.feature_importances_})\n",
    "    return importances.sort_values(\"importance\", ascending=False)[:n_display]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3c59f594-4aee-4cd9-81f4-906dba34b856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>win_rate_3_1Y_before_j</td>\n",
       "      <td>4244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>win_rate_3_1Y_before_t</td>\n",
       "      <td>4223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>peds_4</td>\n",
       "      <td>4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prize_1Y_before_j</td>\n",
       "      <td>4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>peds_0</td>\n",
       "      <td>4037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>prize_1Y_before_t</td>\n",
       "      <td>3983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>win_rate_1_1Y_before_t</td>\n",
       "      <td>3969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>odds_1R_before</td>\n",
       "      <td>3751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>win_rate_1_1Y_before_j</td>\n",
       "      <td>3727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>course_len_all</td>\n",
       "      <td>3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>odds_3R_before</td>\n",
       "      <td>3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>odds_2R_before</td>\n",
       "      <td>3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interval</td>\n",
       "      <td>3078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>horse_number</td>\n",
       "      <td>2339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>final_plus_rank</td>\n",
       "      <td>2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>course_len</td>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>money_rank</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time_rank_p</td>\n",
       "      <td>1811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_horses</td>\n",
       "      <td>1751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>rank_rank</td>\n",
       "      <td>1716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>course_len_dif</td>\n",
       "      <td>1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weight_j</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>race_park_阪神</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>race_park_小倉</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>race_park_福島</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>race_type_芝</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>race_park_京都</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>race_park_新潟</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>race_park_東京</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>race_type_ダート</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>race_park_函館</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>race_condition_重</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sex_牡</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>race_park_中京</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>race_condition_不良</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>weather_雨</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>race_turn_右</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sex_牝</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>race_turn_左</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>race_condition_稍重</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>race_park_中山</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>race_condition_良</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sex_セ</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>weather_晴</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>weather_曇</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>race_turn_ー</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>race_park_札幌</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>race_type_障害</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>race_turn_直</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>weather_小雨</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>race_turn_芝</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>weather_小雪</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weather_雪</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  importance\n",
       "15  win_rate_3_1Y_before_j        4244\n",
       "18  win_rate_3_1Y_before_t        4223\n",
       "13                  peds_4        4180\n",
       "16       prize_1Y_before_j        4091\n",
       "12                  peds_0        4037\n",
       "19       prize_1Y_before_t        3983\n",
       "17  win_rate_1_1Y_before_t        3969\n",
       "5           odds_1R_before        3751\n",
       "14  win_rate_1_1Y_before_j        3727\n",
       "8           course_len_all        3724\n",
       "7           odds_3R_before        3690\n",
       "6           odds_2R_before        3689\n",
       "10                interval        3078\n",
       "0             horse_number        2339\n",
       "52         final_plus_rank        2274\n",
       "3               course_len        2036\n",
       "51              money_rank        1923\n",
       "9              time_rank_p        1811\n",
       "4                 n_horses        1751\n",
       "53               rank_rank        1716\n",
       "11          course_len_dif        1625\n",
       "2                 weight_j        1471\n",
       "1                      age        1338\n",
       "45            race_park_阪神         162\n",
       "43            race_park_小倉         152\n",
       "50            race_park_福島         146\n",
       "31             race_type_芝         138\n",
       "47            race_park_京都         130\n",
       "42            race_park_新潟         129\n",
       "48            race_park_東京         123\n",
       "32           race_type_ダート         123\n",
       "46            race_park_函館         105\n",
       "36        race_condition_重          98\n",
       "38                   sex_牡          95\n",
       "49            race_park_中京          92\n",
       "37       race_condition_不良          91\n",
       "27               weather_雨          85\n",
       "20             race_turn_右          74\n",
       "39                   sex_牝          71\n",
       "21             race_turn_左          59\n",
       "35       race_condition_稍重          58\n",
       "44            race_park_中山          54\n",
       "34        race_condition_良          53\n",
       "40                   sex_セ          51\n",
       "25               weather_晴          46\n",
       "26               weather_曇          40\n",
       "24             race_turn_ー          34\n",
       "41            race_park_札幌          29\n",
       "33            race_type_障害          24\n",
       "22             race_turn_直          23\n",
       "28              weather_小雨          22\n",
       "23             race_turn_芝          22\n",
       "30              weather_小雪           1\n",
       "29               weather_雪           0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance(X_test,n_display=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ebb1ed9-4c9c-4831-9ab3-943ed9a9de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf.params={\n",
    "'objective': 'binary',\n",
    " 'random_state': 100,\n",
    " 'metric': 'auc',\n",
    " 'boosting': 'gbdt',\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 6.139101771748524,\n",
    " 'lambda_l2': 0.5888941495818154,\n",
    " 'num_leaves': 25,\n",
    " 'feature_fraction': 0.44800000000000006,\n",
    " 'bagging_fraction': 1.0,\n",
    " 'bagging_freq': 0,\n",
    " 'min_child_samples': 20,\n",
    " 'num_iterations': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "135d782a-0d4c-43b9-bb70-c4421b655cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = bz2.BZ2File('data/HorecastModel_3.bz2', 'rb')\n",
    "lgb_clf = pickle.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09b88c2d-91c5-4696-b717-b3656960e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: axis\n",
      "正解率(test) 0.816800106554587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('正解率(test)',accuracy_score(y_test, lgb_clf.predict(X_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8df0985d-1778-4d47-b327-16af5b86979d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: axis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6232046408634466"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,lgb_clf.predict(X_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ad7290f5-80c3-4443-a1f2-48bb8e18c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f1fa4b37-1bae-4992-97f9-449a2fb0ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = pickle5.dump(lgb_clf, open('data/HorecastModel_4.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "346cbf14-03e9-4514-8bfb-387e73c75c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "compressionLevel = 9\n",
    "source_file = 'data/HorecastModel_4.pickle' # this file can be in a different format, like .csv or others...\n",
    "destination_file = 'data/HorecastModel_4.bz2'\n",
    "\n",
    "with open(source_file, 'rb') as data:\n",
    "    tarbz2contents = bz2.compress(data.read(), compressionLevel)\n",
    "    \n",
    "fh = open(destination_file, \"wb\")\n",
    "fh.write(tarbz2contents)\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0bb84c-3e60-4d43-b864-059ffc008002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
